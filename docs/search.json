[
  {
    "objectID": "mod-4-0-overview.html",
    "href": "mod-4-0-overview.html",
    "title": "19  Module 4 Overview",
    "section": "",
    "text": "19.1 Introduction\nWelcome to Module 4 of ECON 700.\nThis module introduces the foundational concepts of probability as a measure of uncertainty and likelihood. Students learn how random experiments generate outcomes that form a sample space, and how probability quantifies the chance that specific outcomes occur. The module progresses through the building blocks of probability theory, including combinations, permutations, complements, unions, and intersections of events. Through these principles, students develop an understanding of mutually exclusive and independent events and how they shape probability calculations.\nThe second half of the module applies probability rules to real-world decision-making and data analysis. Learners explore conditional probability, the multiplication and addition laws, and the distinction between joint and marginal probabilities. The module culminates in an introduction to Bayes’ Theorem, illustrating how prior beliefs are updated with new evidence—first conceptually, then through applications like medical testing and the Monty Hall problem. This approach emphasizes the interpretive and practical power of probability in economic reasoning, uncertainty, and risk assessment.",
    "crumbs": [
      "Introduction to Probability",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Module 4 Overview</span>"
    ]
  },
  {
    "objectID": "mod-4-0-overview.html#learning-objectives",
    "href": "mod-4-0-overview.html#learning-objectives",
    "title": "19  Module 4 Overview",
    "section": "19.2 Learning Objectives",
    "text": "19.2 Learning Objectives\nBy the end of this module, you should be able to:\n\nDefine key probability concepts, including random experiments, sample spaces, and events.\nCompute probabilities using basic rules (addition, multiplication, complement) for mutually exclusive and independent events.\nDifferentiate between permutations and combinations in counting possible outcomes.\nInterpret conditional probabilities and construct joint and marginal probability tables.\nApply Bayes’ Theorem to update probabilities based on new information.\nAnalyze real-world scenarios, such as the Monty Hall problem or medical testing, to evaluate decision-making under uncertainty.",
    "crumbs": [
      "Introduction to Probability",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Module 4 Overview</span>"
    ]
  },
  {
    "objectID": "mod-4-0-overview.html#readings-resources",
    "href": "mod-4-0-overview.html#readings-resources",
    "title": "19  Module 4 Overview",
    "section": "19.3 Readings & Resources",
    "text": "19.3 Readings & Resources\n\nBarbara Illowsky and Susan Dean. Introductory Statistics 2e. OpenStax. (Chapter 3). Available for free online at https://openstax.org/books/introductory-statistics-2e/pages/2-introduction\nIrizarry, R. (2025). Introduction to Data Science: Statistics and Prediction Algorithms Through Case Studies (Chapters 1-3). Available for free at: https://rafalab.dfci.harvard.edu/dsbook-part-2/\nWickham, H., & Grolemund, G. (2017). R for Data Science. (Chapters 1–3).\nOnline R documentation: https://cran.r-project.org/manuals.html\nRStudio Cheat Sheets",
    "crumbs": [
      "Introduction to Probability",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Module 4 Overview</span>"
    ]
  },
  {
    "objectID": "mod-4-0-overview.html#activities",
    "href": "mod-4-0-overview.html#activities",
    "title": "19  Module 4 Overview",
    "section": "19.4 Activities",
    "text": "19.4 Activities\n\nComplete the hands-on coding exercises embedded in each lesson.\n\nComplete the weekly class assignment.\n\nParticipate in the discussion form.\n\nTake the weekly knowledge quiz.",
    "crumbs": [
      "Introduction to Probability",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Module 4 Overview</span>"
    ]
  },
  {
    "objectID": "mod-4-0-overview.html#lessons-in-this-module",
    "href": "mod-4-0-overview.html#lessons-in-this-module",
    "title": "19  Module 4 Overview",
    "section": "19.5 Lessons in this Module",
    "text": "19.5 Lessons in this Module\n\n4.1 – Introduction to Probability\n4.2 – Probability Rules\n4.3 – Conditional Probability\n\n\nNext: Start with Introduction to Probability.",
    "crumbs": [
      "Introduction to Probability",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Module 4 Overview</span>"
    ]
  },
  {
    "objectID": "mod-4-1-probability.html",
    "href": "mod-4-1-probability.html",
    "title": "20  Introduction to Probability",
    "section": "",
    "text": "20.1 Defining Probablity\nProbability is a measure of the likelihood that an outcome will occur.\nIf a fair coin has tails on one side and heads on the other side, we understand, over thousands of flips (trials), that we will observe heads 50% of the time and tails 50% of the time. Assuming that no flips end up on the edge, the likelihood of heads for a fair coin is 0.50 while the likelihood of tails is 0.50.\nProbability is a numerical measure of the likelihood of an outcome and is bounded between 0 and 1, including 0 and 1. If the probability of an outcome is ‘close’ to zero, then it is likely to occur than an outcome that is ‘closer’ to 1.\nIn other words, if the outcome of the outcome is beneficial (winning a prize), we would prefer that the probability of the outcome be higher (closer to 1) than lower. Likewise, if the outcome of the outcome if not beneficial (incurring a costly bill), we would prefer the probability of the outcome be lower (closer to 0) than higher.",
    "crumbs": [
      "Introduction to Probability",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduction to Probability</span>"
    ]
  },
  {
    "objectID": "mod-4-1-probability.html#experiments-and-randomness",
    "href": "mod-4-1-probability.html#experiments-and-randomness",
    "title": "20  Introduction to Probability",
    "section": "20.2 Experiments and Randomness",
    "text": "20.2 Experiments and Randomness\nA random experiment is a process that generates outcomes.\nIn our coin flipping example, the process of flipping the coin generates two possible outcomes, heads or tails. The outcomes are well defined prior to the start of the experiment and the outcomes are mutually exclusive. In other words, an outcome must be either heads or tails and there is not a possible outcome where heads and tails occur simultaneously.\nEach repetition of the experiment is a trial.\nAn experiment may consist of one trial, several trials, or many trials. However many trials there are in an experiment, the outcome of each trial is a random event, that is, the outcome is not pre-determined and occurs by chance.\nConsider an unfair six-sided die that is weighted so that it lands on six on every throw. Throwing the die is not a random experiment because the outcome of every trial is known prior to the experiment. Regardless of whether you throw the die one time or fifty times, the outcome is always six. Now compare this to a fair six sided die. On any given trial, the die could land on 1, 2, 3, 4, 5, or 6. The outcome of any specific trial is unknown prior to its occurrence but, over repeated trials, we know the probability of each outcome.\nWe have now discussed two random experiments, the flipping of a fair coin and the toss of a fair six sided tie. In the case of the fair coin, we have identified two possible outcomes: heads and tails. In the case of the fair six sided die, we have identified six possible outcomes: 1, 2, 3, 4, 5, and 6.\nThe set of possible outcomes for each random experiment is known as the sample space.\nThe sample space consists of the mutually exclusive and collectively exhaustive outcomes of a random experiment.\nMutually exclusive implies that a random experiment cannot have the same outcome simultaneously.\nCollectively exhaustive implies that all the outcomes of the random experiment are contained in the sample space.",
    "crumbs": [
      "Introduction to Probability",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduction to Probability</span>"
    ]
  },
  {
    "objectID": "mod-4-1-probability.html#multistep-counting-rules",
    "href": "mod-4-1-probability.html#multistep-counting-rules",
    "title": "20  Introduction to Probability",
    "section": "20.3 Multistep Counting Rules",
    "text": "20.3 Multistep Counting Rules\nConsider a fair 10-sided tie.\nThe potential outcomes of any trial are\n\\[s = \\{1, 2, 3, 4, 5, 6, 7, 8 , 9, 10\\}\\] What happens if we conduct two trails?\nThere are ten possible outcomes of the first trial and ten possible outcomes in the second trial. But what are number of outcomes for the multistep experiment?\nAssume that you roll a 1 on the first trial. The set of possible outcomes of the first trial \\(o_1\\) are:\n\\[o_1 = \\{(1,1), (1,2), (1,3), (1,4), (1,5), (1,6), (1,7), (1,8), (1,9), (1,10) \\}\\]\nAnd if you roll a 2 on the first trial, then the set of possible outcomes are:\n\\[o_2 = \\{(2,1), (2,2), (2,3), (2,4), (2,5), (2,6), (2,7), (2,8), (2,9), (2,10) \\}\\]\nIf the first roll produces a 1, there are 10 possible outcomes. If the first roll produces a 2, there are 10 different outcomes, and so on.\nExtending this logic yields 100 possible outcomes for the two trial experiment with a fair ten-sided tie.\nGiven a random experiment with a sequence of \\(k\\)-steps and \\(n_1, n_2, ..., n_k\\) outcomes for each step, then the number of outcomes in the sample space is equal to:\n\\[n_1 \\times n_2 \\times ... \\times n_k\\] The random experiment of rolling a 10-sided die two times has \\(k = 2\\) steps and the number of outcomes of each step is equal to \\(n_1 = 10, n_2 = 10\\). The number of outcomes is equal to\n\\[n_1 \\times n_2 = 10 \\times 10 = 100\\]",
    "crumbs": [
      "Introduction to Probability",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduction to Probability</span>"
    ]
  },
  {
    "objectID": "mod-4-1-probability.html#multistep-examples",
    "href": "mod-4-1-probability.html#multistep-examples",
    "title": "20  Introduction to Probability",
    "section": "20.4 Multistep Examples",
    "text": "20.4 Multistep Examples\nIn our first example, assume we are flipping a fair two-sided coin five times.\nGiven that \\(k = 5\\) and \\(n_1 = 5, n_2 = 5, n_3 = 5, n_4 = 5, n_5 = 5\\), then number outcomes in the sample space of the random experiment is equal to:\n\\[s = n_1 \\times n_2 \\times n_3 \\times n_4 \\times n_5 = 2 \\times 2 \\times 2 \\times 2 \\times 2 = 2^5 = 32\\]\nIn our second example, assume that we are throwing a fair six-sided die followed by a fair two-sided coin followed by a fair twenty-sided die.\nGiven that \\(k =3\\) and \\(n_1 = 6, n_2 = 2, n_3 = 20\\), then the number of outcomes in the sample space is equal to:\n\\[n_1 \\times n_2 \\times n_3 = 6 \\times 2 \\times20 = 240\\]",
    "crumbs": [
      "Introduction to Probability",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduction to Probability</span>"
    ]
  },
  {
    "objectID": "mod-4-1-probability.html#factorials",
    "href": "mod-4-1-probability.html#factorials",
    "title": "20  Introduction to Probability",
    "section": "20.5 Factorials",
    "text": "20.5 Factorials\nA factorial is merely a series of products and are indicated by an exclamation mark.\nThe factorial function of a positive integer \\(n\\) is defined as the product of all the positive integers not greater than \\(n\\).\n\\[\nn! = 1 \\times 2 \\times 3\\ \\times 4 \\dots (n-2) \\times (n-1) \\times n\n\\] For example, 5 factorial can be represented as\n\\[\n5! = 5 \\times 4 \\times 3 \\times 2 \\times 1 = 120\n\\]\nIn R, the function factorial allows one to estimate the factorial of a positive integer\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Introduction to Probability",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduction to Probability</span>"
    ]
  },
  {
    "objectID": "mod-4-1-probability.html#combinations",
    "href": "mod-4-1-probability.html#combinations",
    "title": "20  Introduction to Probability",
    "section": "20.6 Combinations",
    "text": "20.6 Combinations\nIn our previous examples, the number of steps and outcomes for each step was relatively small. Determining the number of outcomes in a sample space can quickly become tedious, or, as complexity increases, hard. We can, however, rely on two counting rules to assist us in determining the number of outcomes in a sample space. The difference between the two counting rules is whether the order of the outcomes matters.\nA combination examines the number of ways the objects can be selected, without regard to the order in which they are selected.\nA bowl of vegetable soup contains a different vegetables and the number of vegetables may differ by type. We don’t care about ordering since all the vegetables together make soup.\nAssume we have four objects, and we select one object at a time without replacement.\nHow many ways can the four objects be drawn given we draw one object at a time without replacement?\nLet’s list the possible combinations:\n\nABC\nABD\nACD\nBCD\n\nWhy are there only four combinations? Remember, the order does not matter. In other words, ABC is the same as BCA which is the same as CAB which is the same as BAC and so on.\nAssume now that we have the four objects and we select two objects at a time without replacement.\nAssume the objects are labeled A, B, C, D and the order of drawing is not important (AC is the same as drawing CA), then the number of possible combinations:\n\nAB\nAC\nAD\nBC\nBD\nCD\n\nIn other words, given four objects and two objects are selected at a time, there are six possible combinations.\nLastly, consider the same number of objects (4) and three objects are selected at a time without replacement.\nAssume the objects are labeled A, B, C, D and the order of drawing is not important (AC is the same as drawing CA), then the number of possible combinations:\n\nABC\nABD\nACD\nBCD\n\nThere are four possible combinations.\nObviously, if the number of objects becomes ‘large,’ it would be quite difficult to list all the possible combinations.",
    "crumbs": [
      "Introduction to Probability",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduction to Probability</span>"
    ]
  },
  {
    "objectID": "mod-4-1-probability.html#combination-formula",
    "href": "mod-4-1-probability.html#combination-formula",
    "title": "20  Introduction to Probability",
    "section": "20.7 Combination Formula",
    "text": "20.7 Combination Formula\nThe number of combinations of \\(N\\) objects taken \\(n\\) at a time is equal:\n\\[C_n^N =  \\binom{N}{n} = \\frac{N!}{n!(N-n)!}\\] Returning to the example where there were four objects and one object is selected at a time without replacement, note that \\(N = 4\\) and \\(n = 1\\), we can calculate that there are 4 possible combinations that can be drawn.\n\\[C_1^4 =  \\binom{4}{1} = \\frac{4!}{1!(4-1)!} = \\frac{24}{6} = 4\\]\nReturning to the example where there were four objects and two objects were selected at a time without replacement, note that \\(N = 4\\) and \\(n = 2\\), we can calculate that there are 6 possible combinations that can be drawn.\n\\[C_2^4 =  \\binom{4}{2} = \\frac{4!}{2!(4-2)!} = \\frac{24}{4} = 6\\] Returning to the example where there were four objects and two objects were selected at a time without replacement, note that \\(N = 4\\) and \\(n = 3\\), we can calculate that there are 4 possible combinations that can be drawn.\n\\[C_3^4 =  \\binom{4}{3} = \\frac{4!}{3!(4-3)!} = \\frac{24}{6} = 4\\]",
    "crumbs": [
      "Introduction to Probability",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduction to Probability</span>"
    ]
  },
  {
    "objectID": "mod-4-1-probability.html#combinations-in-r",
    "href": "mod-4-1-probability.html#combinations-in-r",
    "title": "20  Introduction to Probability",
    "section": "20.8 Combinations in R",
    "text": "20.8 Combinations in R\nIn the following examples, we show how to calculate the factorial of a value in R, the manual calculation of combination without replacement, and using the choose} function to calculate the combination without replacement.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Introduction to Probability",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduction to Probability</span>"
    ]
  },
  {
    "objectID": "mod-4-1-probability.html#lottery-example",
    "href": "mod-4-1-probability.html#lottery-example",
    "title": "20  Introduction to Probability",
    "section": "20.9 Lottery Example",
    "text": "20.9 Lottery Example\nA good example is a lottery. Assume that the lottery requires you to pick six numbers from 1 to 70. The numbers are picked without replacement. In other words, there are 70 objects (\\(N\\)) and 6 objects (\\(n\\)) are selected without replacement?\nHow many possible outcomes are there in the sample space for this lottery? The example code below demonstrates how to calculate the number of outcomes in the sample space when there are 70 objects and 6 objects are selected without replacement. There are 131,115,985 possible combinations or outcomes in the sample space for this experiment.\nHowever, lotteries found that larger jackpots attracted more customers. How do you boost the jackpot? One method is to have players pick a number of balls from one set of numbers without replacement and then another ball from another set of numbers. This “megaball” or “powerball” increases the number of possible combinations.\nIn the Virginia lottery Megamillions game, you pick 5 balls from 70 balls and then one ball from a separate 25 balls. The number of possible outcomes is equal to the combination of 70 balls picking 5 without replacement and then 1 ball from 25 possible balls. As you can see in the example below, the number of potential combinations increases to 302,575,350.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Introduction to Probability",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduction to Probability</span>"
    ]
  },
  {
    "objectID": "mod-4-1-probability.html#permutations",
    "href": "mod-4-1-probability.html#permutations",
    "title": "20  Introduction to Probability",
    "section": "20.10 Permutations",
    "text": "20.10 Permutations\nWhile a combination does not require the objects to be drawn in a specific order, a permutation requires a specific ordering of objects.\nOne way to think about permutations is “this, then that.” In other words, one object must be drawn before another object for each possible outcome. Think about throwing a fair six-sided die two times. A roll of 1 on the first throw and 2 on the second throw is different than a roll of 2 on the first roll and 1 on the second roll. The order of selection is important unlike combinations.\nLet \\(N\\) be the number of objects and \\(n\\) are the number of objects that are selected without replacement. The number of permutations of \\(N\\) objects taken \\(n\\) at a time is defined as:\n\\[\nP_n^N = n! \\binom{N}{n} = \\frac{N!}{(N-n)!}\n\\]\nBecause the ordering matters, the number of outcomes from an ordered experiment is higher than the number of outcomes in an unordered experiment. In other words \\(P_n^N \\ge C_n^N\\).\nTo see this, assume that there are four possible objects:\n\nBlack (B)\nGreen (G)\nRed (R)\nWhite (W)\n\nGiven four objects, assume that two objects are selected without replacement.\nCombinations (6): BG, BR, BW, GR, GW, RW\nPermutations (12): BG, BR, BW, GB, GR, GW, RB, RG, RW, WB, WG, WR\nIn the example code below, the number of combinations and permutations are calculated manually.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Introduction to Probability",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduction to Probability</span>"
    ]
  },
  {
    "objectID": "mod-4-1-probability.html#permutation-example",
    "href": "mod-4-1-probability.html#permutation-example",
    "title": "20  Introduction to Probability",
    "section": "20.11 Permutation Example",
    "text": "20.11 Permutation Example\nIn the example code below, the number of combinations and permutations are calculated using the choose and permutations functions.\nThe combination and permutations functions will create a matrix of outcomes for the random experiment.\nThese matrices grow large quickly and it may be more efficient to manually code the combinations and permutations.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Introduction to Probability",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduction to Probability</span>"
    ]
  }
]