[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ECON 700",
    "section": "",
    "text": "0.1 Course Introduction\nNote: The course is under construction. Some links will not work.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ECON 700</span>"
    ]
  },
  {
    "objectID": "index.html#course-introduction",
    "href": "index.html#course-introduction",
    "title": "ECON 700",
    "section": "",
    "text": "Course Objectives and Materials\n\n\nMeet Your Instructor\n\n\nSyllabus",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ECON 700</span>"
    ]
  },
  {
    "objectID": "index.html#module-01-introduction-to-r-and-descriptive-statistics",
    "href": "index.html#module-01-introduction-to-r-and-descriptive-statistics",
    "title": "ECON 700",
    "section": "0.2 Module 01 – Introduction to R and Descriptive Statistics",
    "text": "0.2 Module 01 – Introduction to R and Descriptive Statistics\n\n\nModule 1.0 - Module 1 Overview\n\n\nModule 1.1 - Data and the Challenge of Economic Analysis\n\n\nModule 1.2 – Introduction to R\n\n\nModule 1.3 – Variables and Assignments in R\n\n\nModule 1.4 – Data frames in R\n\n\nModule 1.5 – Using Quarto",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ECON 700</span>"
    ]
  },
  {
    "objectID": "index.html#module-02---descriptive-statistics",
    "href": "index.html#module-02---descriptive-statistics",
    "title": "ECON 700",
    "section": "0.3 Module 02 - Descriptive Statistics",
    "text": "0.3 Module 02 - Descriptive Statistics\n\n\nModule 2.0 - Module 2 Overview\n\n\nModule 2.1 – Frequency Distributions\n\n\nModule 2.2 – Measures of Central Tendency\n\n\nModule 2.3 – Measures of Dispersion\n\n\nModule 2.4 – Z-Scores",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ECON 700</span>"
    ]
  },
  {
    "objectID": "index.html#module-03-covariance-and-correlation",
    "href": "index.html#module-03-covariance-and-correlation",
    "title": "ECON 700",
    "section": "0.4 Module 03 – Covariance and Correlation",
    "text": "0.4 Module 03 – Covariance and Correlation\n\n\nModule 3.0 - Module 3 Overview\n\n\nModule 3.1 - Skewness\n\n\nModule 3.2 - Chebyshev’s Theorem\n\n\nModule 3.3 - Covariance and Correlation\n\n\n\n\nThis site provides interactive and static examples for economic data analysis using R and WebR. Click on the links above to explore each section.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ECON 700</span>"
    ]
  },
  {
    "objectID": "mcnab.html",
    "href": "mcnab.html",
    "title": "2  Meet Your Instructor",
    "section": "",
    "text": "2.1 About\nChair, Department of Economics | rmcnab@odu.edu | 757-683-3153\nProfessor Robert M. McNab currently serves as the Chair of the Department of Economics in the Strome College of Business at Old Dominion University. Dr. McNab is also the Director of the Dragas Center for Economic Analysis and Policy at Old Dominion University. He is a member of the Federal Reserve Bank of Philadelphia’s Survey of Professional Forecasters and, from 2018 to 2022, he was a member of the Joint Advisory Board of Economists for the Commonwealth of Virginia. Professor McNab has published in Applied Economics, Cornell Hospitality Quarterly, Defense and Peace Economics, National Tax Journal, Public Budgeting and Finance, and World Development, among others. He edits the annual State of the Region: Hampton Roads and State of the Commonwealth reports Professor McNab has appeared in the Associated Press, China Global Television Network, CNN, LiveNow from Fox News, Forbes, Newsweek, Wall Street Journal, Washington Post, Welt am Sonntag, Yahoo News, Yahoo Finance, Richmond Times-Dispatch, Virginian Pilot, Virginia Public Media, and Daily Press, among others. Dr. McNab joined the faculty of the Department of Economics in the Strome College of Business of Old Dominion University in July 2016 and previously was a member of the faculty of the Naval Postgraduate School in Monterey, California from 2000 to 2016.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Meet Your Instructor</span>"
    ]
  },
  {
    "objectID": "mcnab.html#contact-policy",
    "href": "mcnab.html#contact-policy",
    "title": "2  Meet Your Instructor",
    "section": "2.2 Contact Policy",
    "text": "2.2 Contact Policy\nStudents should feel welcome to contact me via email at rmcnab@odu.edu or drop by Zoom office hours. I strongly encourage students to communicate with me. I will try to answer emails within 48 business hours (often much sooner) for course related topics.\nStudents should take the time to craft complete, professional emails. The more information that you can provide about a question or problem, the more likely that my response will be helpful. Avoid non-professional language and practice communicating in the corporate workplace. Emails that are unprofessional will be returned with no action.\nStudents should proactively address issues with the class and scheduling rather than waiting until an assignment or case study discussion is overdue. In many cases, accommodations can be made for ‘life events,’ however, clear and prompt communication is necessary.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Meet Your Instructor</span>"
    ]
  },
  {
    "objectID": "mcnab.html#virtual-office-hours",
    "href": "mcnab.html#virtual-office-hours",
    "title": "2  Meet Your Instructor",
    "section": "2.3 Virtual Office Hours",
    "text": "2.3 Virtual Office Hours\nOffice hours will be held on a rotating schedule and are available by appointment. Check the class announcements for the schedule of office hours, which vary to accommodate students with different schedules.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Meet Your Instructor</span>"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "3  Course Objectives",
    "section": "",
    "text": "3.1 ECON 700",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Course Objectives</span>"
    ]
  },
  {
    "objectID": "about.html#course-learning-objectives",
    "href": "about.html#course-learning-objectives",
    "title": "3  Course Objectives",
    "section": "3.2 Course Learning Objectives",
    "text": "3.2 Course Learning Objectives\n\nFormulate economic research questions and testable hypotheses that can be examined using publicly available data sources.\nAcquire, manage, and prepare economic data by applying programming techniques in R, including data extraction from APIs and other official sources.\nApply descriptive statistics, probability concepts, and sampling methods to summarize, visualize, and interpret economic data.\nConduct hypothesis testing and interval estimation to draw valid inferences from economic and financial data.\nUtilize R and RStudio to implement statistical techniques and effectively communicate results through reproducible code, visualizations, and written analysis.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Course Objectives</span>"
    ]
  },
  {
    "objectID": "about.html#textbooks-and-materials",
    "href": "about.html#textbooks-and-materials",
    "title": "3  Course Objectives",
    "section": "3.3 Textbooks and Materials",
    "text": "3.3 Textbooks and Materials\nThe required textbooks are an integral part of the class. Students should expect to read the textbooks prior to class and to be prepared to answer discussion questions from the textbook. These textbooks provide a foundation upon which the course is built and students will succeed if they take the time to read and review the material in the textbooks.\nThe first textbook (Hanck, et. al.) provides students with an introduction to applied econometrics using the R programming language. The second textbook (Irizarry) provides an introduction to data science methods using R and covers many of the same topics that we discuss in class. These textbooks are free.\nAs this course focuses on the learning and application of statistical techniques, a computer with R and R Studio installed is necessary. You will need access to a laptop, tablet, or other computing device to complete the assignments and and exams.\nYou may also use R Studio Cloud instead of a locally installed version of R.\nYou can create a free R-Studio cloud account at &lt;[https://posit.co/download/rstudio-desktop/&gt;\nAll other course materials are on Canvas or can be accessed through Canvas. You are required to know how to use Canvas to access and submit assignments, quizzes, and examinations. You should also be comfortable using ODU email to communicate.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Course Objectives</span>"
    ]
  },
  {
    "objectID": "about.html#required-texts",
    "href": "about.html#required-texts",
    "title": "3  Course Objectives",
    "section": "3.4 Required Texts",
    "text": "3.4 Required Texts\nBarbara Illowsky and Susan Dean. Introductory Statistics 2e. OpenStax. Available for free online at https://openstax.org/books/introductory-statistics-2e/pages/1-introduction\nChristoph Hanck, Martin Arnold, Alexander Gerber,and Martin Schmelzer. Introduction to Econometrics with R. Available for free online at https://www.econometrics-with-r.org, 2025.\nRafael A. Irizarry. Introduction to Data Science: Data Wrangling and Visualization with R. Available for free at https://rafalab.dfci.harvard.edu/dsbook-part-1/.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Course Objectives</span>"
    ]
  },
  {
    "objectID": "about.html#reference-texts",
    "href": "about.html#reference-texts",
    "title": "3  Course Objectives",
    "section": "3.5 Reference Texts",
    "text": "3.5 Reference Texts\nDavid R. Anderson, Dennis J. Sweeney, Thomas A. Williams, Jeffrey D. Camm, and James J. Cochran. Statistics for Business and Economics 14th Edition. Earlier editions will suffice.\nAngrist, J.D. & Pischke, Jorn-Steffen. (2013). Mostly Harmless Econometrics: An Empiricist’s Companion. Content Technologies Inc.\nBaruffa, O. (2022). The Big Book of R. Available for free at: https://www.bigbookofr.com/\nChan, S. (2021) Introduction to Probability for Data Science. Michigan Publishing. Available for free at: https://probability4datascience.com\nKennedy, P. (2003). A Guide to Econometrics. MIT Press.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Course Objectives</span>"
    ]
  },
  {
    "objectID": "mod-1-0-overview.html",
    "href": "mod-1-0-overview.html",
    "title": "4  Module 1 Overview",
    "section": "",
    "text": "4.1 Introduction\nWelcome to Module 1 of ECON 700.\nIn this module, you will be introduced to R and the RStudio environment.\nYou will also start working with data in R.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Module 1 Overview</span>"
    ]
  },
  {
    "objectID": "mod-1-0-overview.html#learning-objectives",
    "href": "mod-1-0-overview.html#learning-objectives",
    "title": "4  Module 1 Overview",
    "section": "4.2 Learning Objectives",
    "text": "4.2 Learning Objectives\nBy the end of this module, you should be able to:\n\nInstall and navigate R and RStudio.\n\nUnderstand R’s basic syntax and data types.\n\nWork with variables and simple operations in R.\n\nImport, view, and explore datasets.\n\nApply descriptive statistics for initial data exploration.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Module 1 Overview</span>"
    ]
  },
  {
    "objectID": "mod-1-0-overview.html#readings-resources",
    "href": "mod-1-0-overview.html#readings-resources",
    "title": "4  Module 1 Overview",
    "section": "4.3 Readings & Resources",
    "text": "4.3 Readings & Resources\n\nBarbara Illowsky and Susan Dean. Introductory Statistics 2e. OpenStax. (Chapter 1). Available for free online at https://openstax.org/books/introductory-statistics-2e/pages/1-introduction\nIrizarry, R. (2025). Introduction to Data Science: Data Wrangling and Visualization with R. (Chapters 1-2). Available for free at: https://rafalab.dfci.harvard.edu/dsbook-part-1/\nWickham, H., & Grolemund, G. (2017). R for Data Science. (Chapters 1–3).\nOnline R documentation: https://cran.r-project.org/manuals.html\nRStudio Cheat Sheets",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Module 1 Overview</span>"
    ]
  },
  {
    "objectID": "mod-1-0-overview.html#activities",
    "href": "mod-1-0-overview.html#activities",
    "title": "4  Module 1 Overview",
    "section": "4.4 Activities",
    "text": "4.4 Activities\n\nComplete the hands-on coding exercises embedded in each lesson.\n\nUse WebR to experiment directly in your browser.\n\nComplete the weekly class assignment.\n\nParticipate in the discussion form.\n\nTake the weekly knowledge quiz.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Module 1 Overview</span>"
    ]
  },
  {
    "objectID": "mod-1-0-overview.html#lessons-in-this-module",
    "href": "mod-1-0-overview.html#lessons-in-this-module",
    "title": "4  Module 1 Overview",
    "section": "4.5 Lessons in this Module",
    "text": "4.5 Lessons in this Module\n\n1.1 – Introduction to Economic Analysis\n\n1.2 – Introduction to R\n\n1.3 – Variables in R\n\n1.4 - Data frames in R\n\n\nNext: Start with Economic Analysis.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Module 1 Overview</span>"
    ]
  },
  {
    "objectID": "mod-1-1-intro-to-data.html",
    "href": "mod-1-1-intro-to-data.html",
    "title": "5  Economic Analysis",
    "section": "",
    "text": "5.1 Data and the Challenge of Economic Analysis\nWe are awash in data. The challenge is to find the right data at the appropriate time to investigate an empirical question of interest. In some cases, the data are well defined, consistently formatted, readily available, and structured to facilitate analysis. Then there are data that could help answer a question, but are not in an easily accessible format. But, before tackling these problems, we need to ask the simple question:\nWhat are data?\nThe Merriam-Webster dictionary defines data as: “…factual information (such as measurements or statistics) used a basis for reasoning, discussion, or calculation.” Broadly speaking, data can consist of measurements regarding the health of individuals, performance of firms, the income of regions, the inflation rate of a national economy, among other things. Data can also consist of statistics that describe the properties of an underlying set of measurements.\nThe Bureau of Labor Statistics (BLS) defines the civilian labor force as “The labor force includes all people age 16 and older who are classified as either employed and unemployed. Conceptually, the labor force level is the number of people who are either working or actively looking for work.”\nHow many people are the in the civilian labor force in the United States? How many in Virginia? Is the labor force larger today than it was at the same time last year? How does the growth in the labor force in Virginia compare to other states? All these questions require obtaining data and, for some, manipulating data to create statistics about the properties of the data.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Economic Analysis</span>"
    ]
  },
  {
    "objectID": "mod-1-1-intro-to-data.html#headline-unemployment-rate",
    "href": "mod-1-1-intro-to-data.html#headline-unemployment-rate",
    "title": "5  Economic Analysis",
    "section": "5.2 Headline Unemployment Rate",
    "text": "5.2 Headline Unemployment Rate\nThe headline unemployment rate is an example of a measure that has different values across time. Collectively, these measures are data on the headline unemployment rate. This rate is equal to the ratio of the employed persons in the civilian labor force to the civilian labor force.\nIn the following figure, we plot the evolution of the unemployment rate over time.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Economic Analysis</span>"
    ]
  },
  {
    "objectID": "mod-1-1-intro-to-data.html#unemployment-by-race",
    "href": "mod-1-1-intro-to-data.html#unemployment-by-race",
    "title": "5  Economic Analysis",
    "section": "5.3 Unemployment by Race",
    "text": "5.3 Unemployment by Race\nData can consist of measurements of a variable across groups of individuals and time. In the following figure, we present the headline unemployment rate by selected racial groups in the United States. Unlike the national unemployment rate which encompasses all individuals in the civilian labor force, each group represents all individuals by race relative to the civilian labor force by race. We can observe how the responsiveness of the unemployment rate differed by race.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Economic Analysis</span>"
    ]
  },
  {
    "objectID": "mod-1-1-intro-to-data.html#unemployment-rate-for-selected-states",
    "href": "mod-1-1-intro-to-data.html#unemployment-rate-for-selected-states",
    "title": "5  Economic Analysis",
    "section": "5.4 Unemployment Rate for Selected States",
    "text": "5.4 Unemployment Rate for Selected States\nIn the table below, we obtain data on unemployment rates for Virginia, Maryland, North Carolina, West Virginia, and the United States from https://fred.stlouisfed.org or ‘FRED’.\nIn the table, each row corresponds to a geography (state or nation) while each column represents a variable for that geography. Note that only the last period available is represented in the table.\n\n\nUnemployment Rate for Selected Geographies\n\n\nFRED Symbol\nDate of Observation\nValue\nValue in Decimal Form\nGeography\n\n\n\n\nVAUR\n2025-08-01\n3.6\n0.036\nVirginia\n\n\nNCUR\n2025-08-01\n3.7\n0.037\nNorth Carollina\n\n\nWVUR\n2025-08-01\n3.8\n0.038\nWest Virginia\n\n\nMDUR\n2025-08-01\n3.6\n0.036\nMaryland\n\n\nUNRATE\n2025-08-01\n4.3\n0.043\nUnited States",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Economic Analysis</span>"
    ]
  },
  {
    "objectID": "mod-1-1-intro-to-data.html#statistics-and-data",
    "href": "mod-1-1-intro-to-data.html#statistics-and-data",
    "title": "5  Economic Analysis",
    "section": "5.5 Statistics and Data",
    "text": "5.5 Statistics and Data\nThe term statistics can refer to numerical facts such as minimums, maximums, averages, medians, variances, and standard deviations (among others) that describe the properties of data.\nStatistics can also refer to the art and science of collecting, analyzing, interpreting, and presenting data. Statistics can also refer to the art and science of collecting, analyzing, presenting, and interpreting data.\nData are the facts collected, analyzed, and summarized for interpretation and presentation. A data set refers to all the data collected for a specific study.\nData are plural, while a data set is singular.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Economic Analysis</span>"
    ]
  },
  {
    "objectID": "mod-1-1-intro-to-data.html#elements-variables-observations",
    "href": "mod-1-1-intro-to-data.html#elements-variables-observations",
    "title": "5  Economic Analysis",
    "section": "5.6 Elements, Variables, Observations",
    "text": "5.6 Elements, Variables, Observations\nAn element is the entity or entities on which data are collected.\nA variable is a characteristic of interest for the elements.\nAn observation is the set of measurements for an element.\nA data set consists of 1,200 individuals with data concerning individual income and job tenure.\n\n1,200 observations (elements)\n2 variables (income and tenure)\n2,400 data values\n\n\n\n\nExample Data Set\n\n\nIndividual\nIncome\nJob Tenure\n\n\n\n\n1\n23420\n8\n\n\n2\n33239\n10\n\n\n3\n44849\n14\n\n\n4\n54829\n17\n\n\n5\n75793\n39",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Economic Analysis</span>"
    ]
  },
  {
    "objectID": "mod-1-1-intro-to-data.html#measurement",
    "href": "mod-1-1-intro-to-data.html#measurement",
    "title": "5  Economic Analysis",
    "section": "5.7 Measurement",
    "text": "5.7 Measurement\nReferring to the unemployment rate, there are two rows with observations for the selected geographical areas. In other words, the elements are the states on which data are collected and presented in the table. There are six variables in the table: the symbol of the variable from FRED, the date of the observation, the value of the observation, the value of the observation in decimal form, and the geography name of the observation.\nThe table contains different scales of measurement. The date variable contains information on time while the state variable is measured on the nominal scale. The nominal scale is used to identify the observational data, that is, the data in the table are organized by the geographical area of the observation. The data pertaining to the unemployment rate is ordinal data in that the measurements contain numeric information.\nBroadly speaking, data can be classified as categorical or quantitative. In the table, the variable containing the geographical names is categorical. We cannot mathematically manipulate the categorical data (subtracting 1 from Virginia does not produce a meaningful result). We could, however, create a new variable that contains numerical values to represent the categorical data, that is, the new quantitative variable would be a numerical representation of the categorical data.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Economic Analysis</span>"
    ]
  },
  {
    "objectID": "mod-1-1-intro-to-data.html#nominal-scale-of-measurement",
    "href": "mod-1-1-intro-to-data.html#nominal-scale-of-measurement",
    "title": "5  Economic Analysis",
    "section": "5.8 Nominal Scale of Measurement",
    "text": "5.8 Nominal Scale of Measurement\nThe scale of measurement determines the amount of information contained in the data. Data are labels or names used to identify an attribute of an element.\nData may be numeric, non-numeric, or both. Ranking is not implied by the numeric values.\nThe individual’s grade can be represented by a character label (“Freshman”) or a numeric value (1).\n\n\n\nNominal Example\n\n\nObservation\nName\nGrade\nNumeric Grade\n\n\n\n\n1\nBob\nFreshman\n4\n\n\n2\nSally\nSophmore\n3\n\n\n3\nJim\nJunior\n2\n\n\n4\nTony\nFreshman\n4\n\n\n5\nSarah\nSenior\n1",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Economic Analysis</span>"
    ]
  },
  {
    "objectID": "mod-1-1-intro-to-data.html#ordinal-scale-of-measurement",
    "href": "mod-1-1-intro-to-data.html#ordinal-scale-of-measurement",
    "title": "5  Economic Analysis",
    "section": "5.9 Ordinal Scale of Measurement",
    "text": "5.9 Ordinal Scale of Measurement\n\nOrdinal scales of measurement have the same properties as nominal scales of measure.\nThe ordering of the ordinal scale is meaningful.\nData may be numeric, non-numeric, or both.\nThe class rank variable is numeric and the values represent a ranking, that is, the lower the number, the higher the rank in the class of students.\n\n\n\n\nOrdinal Example\n\n\nObs\nName\nGrade\nClass Rank\n\n\n\n\n1\nBob\nFreshman\n3\n\n\n2\nSally\nFreshman\n5\n\n\n3\nJim\nFreshman\n29\n\n\n4\nTony\nFreshman\n55\n\n\n5\nSarah\nFreshamn\n144",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Economic Analysis</span>"
    ]
  },
  {
    "objectID": "mod-1-1-intro-to-data.html#interval-scale-of-measurement",
    "href": "mod-1-1-intro-to-data.html#interval-scale-of-measurement",
    "title": "5  Economic Analysis",
    "section": "5.10 Interval Scale of Measurement",
    "text": "5.10 Interval Scale of Measurement\n\nInterval scales of measurement have the same properties as ordinal scales of measurement.\nThe ranking of the scale contains information.\nThe intervals between observations contain information.\nInterval data are always numeric.\nThe SAT score is ordinal while the difference between the highest scoring student and another student is an interval measure.\n\n\n\n\nInterval Example\n\n\nObs\nName\nSAT Score (Ordinal)\nInterval to Bob\n\n\n\n\n1\nBob\n1580\n0\n\n\n2\nSally\n1320\n260\n\n\n3\nJim\n1110\n470\n\n\n4\nTony\n1052\n528\n\n\n5\nSarah\n952\n628",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Economic Analysis</span>"
    ]
  },
  {
    "objectID": "mod-1-1-intro-to-data.html#ratio-scale-of-measurement",
    "href": "mod-1-1-intro-to-data.html#ratio-scale-of-measurement",
    "title": "5  Economic Analysis",
    "section": "5.11 Ratio Scale of Measurement",
    "text": "5.11 Ratio Scale of Measurement\n\nA ratio scale of measurement has the properties of the interval scale and the ratio of the two values is useful.\nThe ratio is numeric and zero is a possible value.\nCare must be taken to define and interpret the ratio data.\nStudents take a physical fitness test with across three events with a maximum possible score of 300 points.\nThe ratio represents the percentage score of each student relative to the maximum score on the test.\n\n\n\n\nRatio Example\n\n\nObs\nName\nRaw Score (300 Max)\nRatio\n\n\n\n\n1\nBob\n248\n0.83\n\n\n2\nSally\n232\n0.77\n\n\n3\nJim\n178\n0.59\n\n\n4\nTony\n157\n0.52\n\n\n5\nSarah\n109\n0.36",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Economic Analysis</span>"
    ]
  },
  {
    "objectID": "mod-1-1-intro-to-data.html#categorical-measures",
    "href": "mod-1-1-intro-to-data.html#categorical-measures",
    "title": "5  Economic Analysis",
    "section": "5.12 Categorical Measures",
    "text": "5.12 Categorical Measures\n\nCategorical variables represent types of data which may be divided into groups.\nLabels or names identify an attribute of each observation.\nCategorical and qualitative data may be used synomously.\nCan be numeric or non-numeric.\nCan be nominal or ordinal scale of measurement.\n\n\n\n\nCategorical Example\n\n\nObs\nName\nRace\nOpinion\n\n\n\n\n1\nBob\nBlack\nAgree\n\n\n2\nSally\nWhite\nDisagree\n\n\n3\nJim\nAsian\nNone\n\n\n4\nTony\nWhite\nAgree\n\n\n5\nSarah\nBlack\nStrongly Agree",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Economic Analysis</span>"
    ]
  },
  {
    "objectID": "mod-1-1-intro-to-data.html#quantitative-versus-qualitative-data",
    "href": "mod-1-1-intro-to-data.html#quantitative-versus-qualitative-data",
    "title": "5  Economic Analysis",
    "section": "5.13 Quantitative versus Qualitative Data",
    "text": "5.13 Quantitative versus Qualitative Data\n\nQuantitative data capture how many or how much.\nQuantitative data are always numeric.\nQuantitative data may ordinal, ranked, interval, ratio or a combination of all types of scales.\nQuantitative data may capture how many or how much but may also capture non-quantitative information.\nOpinion surveys, for example, may ask provide a numeric scale from strongly agree (1) to strongly disagree (5).\nThe numeric measure is a proxy for the strength of agreement or disagreement.\nIn many instances, qualitative responses are transformed into numerical representations to allow for quantatitive analysis.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Economic Analysis</span>"
    ]
  },
  {
    "objectID": "mod-1-1-intro-to-data.html#cross-sectional-time-series-and-panel-data",
    "href": "mod-1-1-intro-to-data.html#cross-sectional-time-series-and-panel-data",
    "title": "5  Economic Analysis",
    "section": "5.14 Cross-Sectional, Time Series, and Panel Data",
    "text": "5.14 Cross-Sectional, Time Series, and Panel Data\nThere are three broad types of data. Let’s establish some terminology. When we discuss data, we often refer to individuals and time. In this context, individuals can represent people, firms, airlines, cars, or some other characteristic that defines the unique observations.\nFor example, if we had data on the average fuel mileage of passenger vehicles in 2019, then individuals would refer to each type of passenger vehicle. If we had randomized data on 100,000 taxpayers in Virginia for 2018, then individuals would refer to unique taxpayers. Lastly, if we collected data on airplane arrivals at Dulles International Airport for each day in 2019, then we would have individual observations across time. We could organize this data by plane registration, airline, or country of origin, or some other category of interest.\nCross-sectional data are data collected across individuals at the same point of time. There is no depth to cross-sectional data, that is, the data represent a snapshot at a specific point in time.\nTime series data are data collected over several time periods. Data for the headline unemployment graph for the United States are time series data.In this context, time series data refers to one variable across time. One can have a collection of time series variables (inflation rate, unemployment rate, and so on). Time series data has depth but not breadth.\nPanel data are data collected across individuals and time. If we collected data for the unemployment rate across states from 2013 to 2025, then we would have individuals (states) and time (months) as defining characteristics of our data. Panel data has breadth (across individuals) and depth (across time).",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Economic Analysis</span>"
    ]
  },
  {
    "objectID": "mod-1-1-intro-to-data.html#types-of-studies",
    "href": "mod-1-1-intro-to-data.html#types-of-studies",
    "title": "5  Economic Analysis",
    "section": "5.15 Types of Studies",
    "text": "5.15 Types of Studies\n\nObservational\n\nObservational studies are non-experimental studies.\nNo attempt is made (or can be made) to control or influence the variables of interest.\nIf we study the impact of smoking on birth weight, we do not control who smokes and who does not smoke during pregnancy.\nIf we examine how exports influence economic growth across countries, we do not control export policy.\n\nConvenience\n\nA convenience study is the most common method of non-probability sampling.\nObservations are obtained because individuals are available to the researcher.\nThis type of study is cheaper and easier than other types, hence it’s popularity.\nThere is no attempt to control for sampling or to randomly sample the population of interest.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Economic Analysis</span>"
    ]
  },
  {
    "objectID": "mod-1-1-intro-to-data.html#population-versus-sample-data",
    "href": "mod-1-1-intro-to-data.html#population-versus-sample-data",
    "title": "5  Economic Analysis",
    "section": "5.16 Population versus Sample Data",
    "text": "5.16 Population versus Sample Data\nWhen working with data, a question may arise whether it is appropriate to work with the population or a sample.\nThe population represents all the individuals for a particular study while a sample is a subset of the population.\nLet’s say we wanted to calculate the average age of students at Old Dominion University for the Fall 2025 semester. If we had access to student records, this might be a relatively easy exercise. In other words, if we had access to data for the population of students, we could calculate the average age of the student population.\nNow, let’s assume we wanted to calculate the average age for all college students in the United States. The problem has become more difficult. We could try and obtain all the records from all the colleges and universities in the United States but this effort might be costly and complex.\nWe could instead sample different colleges and universities and construct an estimate of the average age of college students. The “closer” our sample is to the population, the better our estimate of the average age of all the college students in the United States. If we only selected colleges and universities with undergraduate programs, our sample would likely understate the average age of college students. If we only selected graduate programs at colleges and universities, our sample would likely overstate the average age of college students.\nThe process by which we use a sample to estimate the properties of the population is statistical inference.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Economic Analysis</span>"
    ]
  },
  {
    "objectID": "mod-1-1-intro-to-data.html#descriptive-statistics",
    "href": "mod-1-1-intro-to-data.html#descriptive-statistics",
    "title": "5  Economic Analysis",
    "section": "5.17 Descriptive Statistics",
    "text": "5.17 Descriptive Statistics\n\nDescriptive statistics are a set of tools used to describe the properties of a set of data.\nDescriptive statistics can be numerical, tabular, or graphical.\nDescriptive statistics typically summarize the properties of the individual observations.\nWe can create a population for 10,000 observations that have a mean of 50.5 and a standard deviation of 10\nWe can then estimate sample averages to describe the mean of the data.\n\nGathering a sample that is representative of the population is the first step. We then must understand the properties of the sample and how this reflects the properties of the population.\n\n# Create a data frame with 10,000 observations\n# mean of the observations is 50.5\n\ndata_1 &lt;- tibble(x1 = rnorm(10000, mean = 50.5, sd = 10))\n\ndata_2 &lt;- slice_sample(data_1, n = 10) %&gt;% \n          summarize(mean_10 = mean(x1))\n\ndata_3 &lt;- slice_sample(data_1, n = 100) %&gt;% \n          summarize(mean_100 = mean(x1))\n\ndata_4 &lt;- slice_sample (data_1, n = 1000) %&gt;% \n          summarize(mean_1000 = mean(x1))\n\ndata_5 &lt;- cbind(data_2, data_3, data_4)\n\nkable(data_5,\n      col.names = c(\"Sample = 10\",\n                    \"Sample = 100\",\n                    \"Sample = 1000\"),\n      align     = c('c', 'c', 'c'),\n      digits    = 2,\n      caption   = 'Sample Averages') %&gt;% \n  column_spec(2:3, width = \"3cm\") %&gt;%\n  kable_styling(full_width = TRUE,\n                font_size  = 10)\n\n\nSample Averages\n\n\nSample = 10\nSample = 100\nSample = 1000\n\n\n\n\n48.28\n50.35\n50.33",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Economic Analysis</span>"
    ]
  },
  {
    "objectID": "mod-1-1-intro-to-data.html#statistical-inference",
    "href": "mod-1-1-intro-to-data.html#statistical-inference",
    "title": "5  Economic Analysis",
    "section": "5.18 Statistical Inference",
    "text": "5.18 Statistical Inference\n\nObtaining data for the population of interest may be difficult, complex, and costly.\nFor cost, complexity, and time considerations, we may use a subset or sample of the population.\nThe decennial Census of the population attempts to count every person in the United States.\nEvery non-Census year, a sample of 1-2 million individuals is taken to estimate the properties of the population.\nStatistical inference is the process of using sample data to make estimates and test hypotheses about the characteristics of the population.\nSince we are using sample data, our estimates are not precise, but come with a measure of error.\nThis course is, at its core, about using sample data to make inferences about the population.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Economic Analysis</span>"
    ]
  },
  {
    "objectID": "mod-1-2-intro-to-r.html",
    "href": "mod-1-2-intro-to-r.html",
    "title": "6  Introduction to R",
    "section": "",
    "text": "6.1 Why use R and RStudio?\nWe will use R and RStudio extensively in this class. You will also use these programs extensively in the following classes on the econometrics sequence.\nA frequently asked question is “why can’t we use Excel?”\nThe simple answer is that Excel is good for some things but R is better for the things we want to do in this and other classes.\nWriting code (programming) allows for:\nOther programs have lower fixed costs than R. These programs, whether Excel, SAS, SPSS, or TSP, have ‘built in’ functions and interfaces that allow ‘easier entry’ than R. In other words, you will invest less time to learn how to start working in other programs than R.\nSo, why then use R? First, coding is like learning a second language. It takes a while to learn the logic and ‘flow’ of the programming language. Second, unlike many other programs, you have a very good idea of what R is doing. If you write code, you learn where data come from, how they are formatted, the properties of data, and you gain a much deeper understanding of the process by which you arrive at an answer.\nAnother strength of this approach is that once you learn to code in R and use RStudio, your marginal cost of learning Python, C++, or SQL is lower because the logic behind each of these languages is similar.\nSimply put, coding is as much about the journey as the destination.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "mod-1-2-intro-to-r.html#why-use-r-and-rstudio",
    "href": "mod-1-2-intro-to-r.html#why-use-r-and-rstudio",
    "title": "6  Introduction to R",
    "section": "",
    "text": "Reproducibility (code provides transparency to processes)\nCustomization (many solutions to a problem)\nAutomation (code once, run many times)\nAccountability (the programmer is responsible for what the code does)",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "mod-1-2-intro-to-r.html#r-and-rstudio-an-introduction",
    "href": "mod-1-2-intro-to-r.html#r-and-rstudio-an-introduction",
    "title": "6  Introduction to R",
    "section": "6.2 R and RStudio: An Introduction",
    "text": "6.2 R and RStudio: An Introduction\nYou will need to install R and RStudio.\nEach is a piece of software. R is the ‘engine’ and RStudio is the interface.\nYou can work with R directly, but RStudio makes the process less painful.\nR is the statistical software package that we will use throughout the course,\nRStudio is an interface that makes using R much easier.\nThe R Project is located at: https://www.r-project.org/",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "mod-1-2-intro-to-r.html#downloading-r",
    "href": "mod-1-2-intro-to-r.html#downloading-r",
    "title": "6  Introduction to R",
    "section": "6.3 Downloading R",
    "text": "6.3 Downloading R\nYou can download R at: https://cloud.r-project.org/\nSelect the correct operating system to download and install R.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "mod-1-2-intro-to-r.html#downloading-rstudio",
    "href": "mod-1-2-intro-to-r.html#downloading-rstudio",
    "title": "6  Introduction to R",
    "section": "6.4 Downloading RStudio",
    "text": "6.4 Downloading RStudio\nYou can download RStudio at: https://posit.co/download/rstudio-desktop/\nNote how Posit tells you to install R and then RStudio.\nYou can also use Posit Cloud from Posit at: https://posit.cloud/",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "mod-1-2-intro-to-r.html#tutorials-in-r",
    "href": "mod-1-2-intro-to-r.html#tutorials-in-r",
    "title": "6  Introduction to R",
    "section": "6.5 Tutorials in R",
    "text": "6.5 Tutorials in R\nThere are numerous tutorials online on how to use R.\nSome overviews that might be helpful:\nThe Big Book of R: https://www.bigbookofr.com/\nGetting Started with R: https://rfortherestofus.com/courses/getting-started/\nR Programming for Beginners: https://youtu.be/fDRa82lxzaU\nR Programming Tutorial: https://youtu.be/_V8eKsto3Ug",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "mod-1-2-intro-to-r.html#how-to-get-better-at-coding",
    "href": "mod-1-2-intro-to-r.html#how-to-get-better-at-coding",
    "title": "6  Introduction to R",
    "section": "6.6 How to Get Better at Coding",
    "text": "6.6 How to Get Better at Coding\nNo coder works alone. Everyone (and yes, I mean everyone) relies on the expertise of others to code.\nWhat does this mean?\nWhen you are working on code, try it yourself first. If something doesn’t work, look for small typos.\nYou can then start asking other resources for help.\nArtificial Intelligence (AI) is helpful to debug code. It can even write code for you, if you know what you are doing.\nRemember, however, that AI is only as good as its algorithm and your prompt. It can (and will) give you answers that are incorrect, answers that appear correct but are wrong, or lead you through solution paths that are inefficient.\nCoding is a dance between what you know and what you can find. The more that you do on your own, the better you will be able to use AI to help you improve (not write) your code.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "mod-1-2-intro-to-r.html#opening-rstudio",
    "href": "mod-1-2-intro-to-r.html#opening-rstudio",
    "title": "6  Introduction to R",
    "section": "6.7 Opening RStudio",
    "text": "6.7 Opening RStudio\n\n\n\nScreenshot of RStudio in Windows\n\n\nWhen you open RStudio for the first time, you will see four panels like in the above image. It is likely that your version of RStudio has a white background with blue or black text.\nIf you would like to change this, go to “Tools &gt; Global Options… &gt; Appearance &gt; Editor theme”.\nYou can choose a darker theme, or leave it a lighter theme.\nThe four panels are as follows:\n\nTop Left: Source – This is where you will write the R code you want to save. In other words, this is where you write and save your work, usually called R scripts (.R files).\nBottom Left: Console – When you execute (or run) code, you will usually see output here. This is also a place you can write code you do not want to be part of your final script. If you were a painter, the Source panel would be your canvas and the Console would be your palette.\nTop Right: Environment – Here is where we will be able to see all the objects (data, etc.) that we are working with in the moment. To clear your environment, use the code rm(list = ls()).\nBottom Right: Output – This is mostly where you will see plots you have generated, but can also see files on your computer, packages you have installed, and “Help” for certain functions.\n\n\n\n\nScreenshot of Rstudio with panel labels.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "mod-1-3-intro-to-r-variables.html",
    "href": "mod-1-3-intro-to-r-variables.html",
    "title": "7  Variables in R",
    "section": "",
    "text": "7.1 Assigning Numeric Values to Variables\nWe can use the assignment operator in R to assign values to a variable. The assignment operator can be thought of as moving a value, character, date, or other form into a named variable.\nThe assignment operator is “&lt;-”.\nThe line, “x2 &lt;- 1056”, means assign the value 1056 to the variable x2.\nIn the code below, we assign the numerical value of 2 to the variable x1 and the numerical value of 4.5 to the variable x2.\nWe can assign the value contained in one variable in another. For example, we can assign x2 to x3 and also specify that the integer value of x2 is assigned to x3.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variables in R</span>"
    ]
  },
  {
    "objectID": "mod-1-3-intro-to-r-variables.html#assigning-numeric-values-to-variables",
    "href": "mod-1-3-intro-to-r-variables.html#assigning-numeric-values-to-variables",
    "title": "7  Variables in R",
    "section": "",
    "text": "Please enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variables in R</span>"
    ]
  },
  {
    "objectID": "mod-1-3-intro-to-r-variables.html#assigning-character-values-to-a-variable",
    "href": "mod-1-3-intro-to-r-variables.html#assigning-character-values-to-a-variable",
    "title": "7  Variables in R",
    "section": "7.2 Assigning Character Values to a Variable",
    "text": "7.2 Assigning Character Values to a Variable\nWe can assign character values to a variable. In the following code, we assign the name “Timothy” as a character to the variable .\nThere is a subtle but important difference to storing a value as a character or as a numeric variable.\nWe assign the or value 06250 to and 06250 as a or value to .\nNote what happens: when stored as a numeric value, 06250 is stored as 6250. When 06250 is stored as “06250” as a character variable, the character variable does not “lose” then “0” in the front of “06250”.\nThis can be very important if you are storing an identification value with a leading 0.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variables in R</span>"
    ]
  },
  {
    "objectID": "mod-1-3-intro-to-r-variables.html#assigning-date-values-to-a-variable",
    "href": "mod-1-3-intro-to-r-variables.html#assigning-date-values-to-a-variable",
    "title": "7  Variables in R",
    "section": "7.3 Assigning Date Values to a Variable",
    "text": "7.3 Assigning Date Values to a Variable\nWe can also store dates and work with dates. We assign 2020-09-01 a date value using the lubridate package. Note that we tell the package that the format of the date is year-month-day (ymd).\nLikewise, we assign 09-05-2020 to date2 as a date variable but tell the package that the format of the date is now month-day-year (mdy).\nNote that even though the dates are in different formats, the lubridate package transforms the dates into a format recognizable by R.\nHaving transformed the date values, we can calculate the time difference by assigning the difference between the two dates to variable date3.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variables in R</span>"
    ]
  },
  {
    "objectID": "mod-1-3-intro-to-r-variables.html#creating-vectors",
    "href": "mod-1-3-intro-to-r-variables.html#creating-vectors",
    "title": "7  Variables in R",
    "section": "7.4 Creating Vectors",
    "text": "7.4 Creating Vectors\nWe can now create a vector that contains several values. In the following example, we combine several numbers and assign them to the variable x5.\nWe can transpose the variable x5. Notice the difference between x5 and its transpose. X5, when output to a table, has five rows and one column. The transpose of X5, when it output to a table, is one row and five columns.\nWe can also combine other variables (if they are the same type) to form a new vector. You can combine single element variables with vectors to create a new vector x6.\nWe can also combine vectors. We create x7 by combining the variables x1, x2, x3, x4 with the vector x5.\n\nrm(list = ls())\n\n#Load packages\n\nlibrary(kableExtra, quiet = TRUE)\n\n# Assign values to x1, x2, x3, x4\n\nx1 &lt;- 1\nx2 &lt;- -5\nx3 &lt;- 136\nx4 &lt;- 0.47\n\n#Create a vector \n\nx5 &lt;- c(12, 13, 14, 25, 100)\n\n#Transpose x5\n\nx6 &lt;- t(x5)\n\n#Use existing variables to create a row vector\n\nx7 &lt;- c(x1, x2, x3, x4, x5)\n\n# Use kable To Create Tables of X5 and X6\n# align = 'c' -&gt; aligns to center\n# digits = 0  -&gt; no decimals\n# col.names -&gt; sets a name for the column\n\nkable(x5,\n      align = 'c',\n      digits = 0,\n      col.names = c('X5'),\n      caption = 'Table Containing Variable X5')\n\nkable(x6,\n      align = 'c',\n      col.names = c('A','B','C','D','E'),\n      caption = 'Table Containing Transpose of X5')\n\nkable(x7,\n      align = 'c',\n      digits = 0,\n      col.names = c('X7'),\n      caption = 'Table Containing Variable X7')\n\n\nTable Containing Variable X5\n\n\nX5\n\n\n\n\n12\n\n\n13\n\n\n14\n\n\n25\n\n\n100\n\n\n\n\nTable Containing Transpose of X5\n\n\nA\nB\nC\nD\nE\n\n\n\n\n12\n13\n14\n25\n100\n\n\n\n\nTable Containing Variable X7\n\n\nX7\n\n\n\n\n1\n\n\n-5\n\n\n136\n\n\n0\n\n\n12\n\n\n13\n\n\n14\n\n\n25\n\n\n100\n\n\n\n\n\nWhen we display x5, for example, we note is a vector 5 elements. We can also directly manipulate x5 by multiplying it by two.\nWe should, however, understand that product of x5 and 2 is not stored, it’s a direct manipulation and not available for future use.\nIf we wanted to store it, we would have to assign it to a variable. Here, we assign the product of x5 and 2 to the variable x8.\n\nrm(list = ls())\n\n#Load packages\n\nlibrary(kableExtra, quiet = TRUE)\n\n#Create a vector \n\nx5 &lt;- c(12, 13, 14, 25, 100)\n\nkable(x5*2,\n      align = 'c',\n      digits = 2,\n      col.names = c('X5 * 2'),\n      caption = 'Table of Variable X5 - Each Element Times 2')\n\n#Assign x5*2 to x8\n\nx8 &lt;- x5*2\n\nkable(x8,\n      align = 'c',\n      digits = 1,\n      col.names = c('X8'),\n      caption = 'Table of Variable X8')\n\n\nTable of Variable X5 - Each Element Times 2\n\n\nX5 * 2\n\n\n\n\n24\n\n\n26\n\n\n28\n\n\n50\n\n\n200\n\n\n\n\nTable of Variable X8\n\n\nX8\n\n\n\n\n24\n\n\n26\n\n\n28\n\n\n50\n\n\n200",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variables in R</span>"
    ]
  },
  {
    "objectID": "mod-1-3-intro-to-r-variables.html#assignment-and-vector-practice",
    "href": "mod-1-3-intro-to-r-variables.html#assignment-and-vector-practice",
    "title": "7  Variables in R",
    "section": "7.5 Assignment and Vector Practice",
    "text": "7.5 Assignment and Vector Practice\nWe have now worked on the basics of assignment elements to vectors and manipulating vectors in R.\nAs practice, try the following.\nCreate a vector made of the following numbers: 5, 10, 12, 24\nCreate a second vector that divides each element of the first vector by 2.\nOutput the second vector to a table.\nYou can build off the example below.\n\nrm(list = ls())\n\nlibrary(kableExtra, quiet = TRUE)\n\nvector_1 &lt;- c(4, 16, 25, 81, 10000)\n\nvector_2 &lt;- sqrt(vector_1)\n\nkable(vector_2,\n      align = 'c',\n      col.names = 'Vector 2')\n\n\n\n\nVector 2\n\n\n\n\n2\n\n\n4\n\n\n5\n\n\n9\n\n\n100",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Variables in R</span>"
    ]
  },
  {
    "objectID": "mod-1-4-intro-to-r-dataframes.html",
    "href": "mod-1-4-intro-to-r-dataframes.html",
    "title": "8  Data frames in R",
    "section": "",
    "text": "8.1 Creating a Data Frame\nSo far, everything we have created has been stored as a variable or vector. A matrix consists of rows and columns. The organization of the matrix is important. In some cases, the rows will correspond to individual observations with variables in the columns. In other cases, the variables are in the rows and individuals in columns. Matrices can contain quantitative and qualitative elements.\nA matrix is a table or a two-dimensional array-like structure. In R, a data frame is a list of variables with the same number of rows with unique row names. If we use the dplyr package, a tibble is similar to a data frame.\nA data frame can have one column with numeric elements, another with date elements, another with character elements, and so on.\nIn the webR code chunk below, we create two vectors, x8 and x9.\nWe can bind these vectors together, that is, ‘merge’ the two vectors. How we choose to put the vectors together is important.\nThere are two functions at our disposal: rbind and cbind.\nThe rbind function “stacks” the observations in the vectors.\nThe cbind function “adds” the column of the second vector to the first vector, creating a data frame with two columns.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data frames in R</span>"
    ]
  },
  {
    "objectID": "mod-1-4-intro-to-r-dataframes.html#creating-a-data-frame",
    "href": "mod-1-4-intro-to-r-dataframes.html#creating-a-data-frame",
    "title": "8  Data frames in R",
    "section": "",
    "text": "8.1.1 Using rbind\nIn the chunk below, we use the rbind function to bind the two vectors together.\nFirst, we bind x9 to x8. We then bind x8 to x9.\nNote that we bind within the kable function. We do not create a new matrix.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n8.1.2 Using cbind\nIn the following chunk, we demonstrate the cbind function, that is, column bind.\nFirst, we bind x9 to x8. We then bind x8 to x9.\nNote that we bind within the kable function. We do not create a new matrix.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data frames in R</span>"
    ]
  },
  {
    "objectID": "mod-1-4-intro-to-r-dataframes.html#creating-a-data-frame-1",
    "href": "mod-1-4-intro-to-r-dataframes.html#creating-a-data-frame-1",
    "title": "8  Data frames in R",
    "section": "8.2 Creating a data frame",
    "text": "8.2 Creating a data frame\nPreviously, we created a matrix by binding two vectors together. We can now create a data frame or tibble.\nA tibble is a more modern version of the standard R data farme. It is part of the tidyverse collection of packages.\nIf you want to learn more about tibbles, see https://tibble.tidyverse.org/\nIn the code chunk below, we again create our two variables. This time, however, we store the two variables in a data frame (original R) and a tibble (new and improved).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data frames in R</span>"
    ]
  },
  {
    "objectID": "mod-1-4-intro-to-r-dataframes.html#using-an-existing-dataframe",
    "href": "mod-1-4-intro-to-r-dataframes.html#using-an-existing-dataframe",
    "title": "8  Data frames in R",
    "section": "8.3 Using an Existing Dataframe",
    "text": "8.3 Using an Existing Dataframe\nR comes with a number of “built in” data sets. For the following discussion, we use the mtcars data. The data contain observations on a number of cars from the Motor Trend magazine.\nOne can work directly with the mtcars data or assign the mtcars data to a data frame. In the following, we assign mtcars to the cardata data frame. We use the assignment operator so that data flows from mtcars to cardata.\nWe can now use the head or tail functions to examine the structure of the cardata data frame. Note that the head function returns the first six rows while the tail function returns the last six rows.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data frames in R</span>"
    ]
  },
  {
    "objectID": "mod-1-4-intro-to-r-dataframes.html#dimensions-of-a-data-frame",
    "href": "mod-1-4-intro-to-r-dataframes.html#dimensions-of-a-data-frame",
    "title": "8  Data frames in R",
    "section": "8.4 Dimensions of a Data Frame",
    "text": "8.4 Dimensions of a Data Frame\nTo find the dimensions of a data frame, we can determine the number of rows and the number of columns separately or together. First, the nrow and ncol functions determine the number of rows and columns in a data frame, respectively.\nWe can also use the dim function to return the dimensions of the data frame. Note that the dim function returns rows then columns.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data frames in R</span>"
    ]
  },
  {
    "objectID": "mod-1-4-intro-to-r-dataframes.html#selecting-rows-or-columns-in-a-data-frame",
    "href": "mod-1-4-intro-to-r-dataframes.html#selecting-rows-or-columns-in-a-data-frame",
    "title": "8  Data frames in R",
    "section": "8.5 Selecting Rows or Columns in a Data Frame",
    "text": "8.5 Selecting Rows or Columns in a Data Frame\nHaving determined the dimensions of the cardata data frame, we can now select parts of the data frame.\nWe can approach this by recognizing that a data frame is organized by rows and columns.\nFor example, mtcars[1,1] returns the value stored in the intersection of the first row and first column in the data frame. The first row in the data frame is for the Mazda RX4 and the first column in the data frame is for miles per gallon, so the intersection of these two produces a value of 21.0. In other words, the Maxda RX4 earns 21.0 miles per gallon.\nSo, in general, for a data frame or tibble, data[row,column].\nFor example, cardata[1:2, 2:3] returns rows 1 to 2 and columns 2 to 3.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIf the row or column is left blank, all values for the column are the result.\nFor example, cardata[,1] would return all rows for the first column of data. On the other hand, cardata[1:2,] would return the first two rows and all the columns.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data frames in R</span>"
    ]
  },
  {
    "objectID": "mod-1-4-intro-to-r-dataframes.html#manipulating-the-dataframe-and-adding-new-variables",
    "href": "mod-1-4-intro-to-r-dataframes.html#manipulating-the-dataframe-and-adding-new-variables",
    "title": "8  Data frames in R",
    "section": "8.6 Manipulating the Dataframe and Adding New Variables",
    "text": "8.6 Manipulating the Dataframe and Adding New Variables\nStarting with the cardata data frame, we can now utilize one of the features of the packages to pipe the data.\nPiping means that the data ‘flows’ in the direction of the pipe. It’s actually called a pipeline of data.\nA bit of housekeeping. We want to convert the rownames in cardata to a variable.\nWe pipe the data frame and then use the function rownames_to_column() to do just that. We then pipe the data to rename the new variable rowname to car.\nWe can now use the mutate function to create a new variable or replace an existing variable.\nIn the following code, the data flow from cardata to the next line of code to create a new variable km_per_gallon using the mutate function.\nImagine a temporary data frame that consists of cardata with a new column for the km_per_gallon variable.\nEach new line of within the mutate} function creates a new variable. The second variable that we create converts kilometers per gallon to kilometers per liter or km_per_liter.\nYour temporary data frame now consists of the cardata data frame plus the two new variables.\nThe third line of the mutate statement creates a new variable that converts miles per gallon into kilometers per liter, essentially duplicating the process of the first two lines of the mutate statement. The new variable is called km2_per_liter.\nAt this point, you decide you only need to keep a subset of variables.\nWe pipe the resulting data frame to the select statement. The variables included in the select statement are kept in the temporary data frame while the variables excluded from the select statement are deleted from the temporary data frame.\nYou have now reached the end of the pipe. The “&lt;-” at the beginning then assigns all the data in the temporary data frame to the cardata2 data frame. Because we have used the grammar of piping, the original data frame is unchanged.\nThe grammar of piping is very useful as it allows you to manipulate a data frame without changing the contents of the original data frame.\nNote how we can start using some of the additional features in the kableExtra package to rename column names for improve presentation.\n\nrm(list = ls())\n\nlibrary(dplyr)\nlibrary(kableExtra)\nlibrary(tidyverse)\n\ncardata &lt;- mtcars \n\ncardata2 &lt;- cardata %&gt;%\n  rownames_to_column() %&gt;%\n  rename(car           = rowname) %&gt;%\n  mutate(km_per_gallon = mpg*1.60934,\n         km_per_liter  = km_per_gallon*3.78541,\n         km2_per_liter = mpg*1.60934*3.78541) %&gt;%\n  select(car, mpg, cyl, wt, km_per_gallon, km_per_liter, km2_per_liter)\n\nkable(cardata[1:5,])\n\nkable(cardata2[1:5,],\n      col.names = c(\"Car\",\n                    \"MPG\",\n                    \"Cylinders\",\n                    \"Weight\",\n                    \"Kilometers per Gallon\",\n                    \"Kliometers per Liter\",\n                    \"Squared KM/Gallon\")) %&gt;%\nkable_classic()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n\n\n\n\n\nCar\n\n\nMPG\n\n\nCylinders\n\n\nWeight\n\n\nKilometers per Gallon\n\n\nKliometers per Liter\n\n\nSquared KM/Gallon\n\n\n\n\n\n\nMazda RX4\n\n\n21.0\n\n\n6\n\n\n2.620\n\n\n33.79614\n\n\n127.9322\n\n\n127.9322\n\n\n\n\nMazda RX4 Wag\n\n\n21.0\n\n\n6\n\n\n2.875\n\n\n33.79614\n\n\n127.9322\n\n\n127.9322\n\n\n\n\nDatsun 710\n\n\n22.8\n\n\n4\n\n\n2.320\n\n\n36.69295\n\n\n138.8979\n\n\n138.8979\n\n\n\n\nHornet 4 Drive\n\n\n21.4\n\n\n6\n\n\n3.215\n\n\n34.43988\n\n\n130.3691\n\n\n130.3691\n\n\n\n\nHornet Sportabout\n\n\n18.7\n\n\n8\n\n\n3.440\n\n\n30.09466\n\n\n113.9206\n\n\n113.9206",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data frames in R</span>"
    ]
  },
  {
    "objectID": "mod-1-4-intro-to-r-dataframes.html#the-fred-api-for-real-gdp",
    "href": "mod-1-4-intro-to-r-dataframes.html#the-fred-api-for-real-gdp",
    "title": "8  Data frames in R",
    "section": "8.7 The FRED API for Real GDP",
    "text": "8.7 The FRED API for Real GDP\nAn Application Programming Interface (API) allows us to obtain data from a source without having to manually downloading the data. In effect, an API allows us to “grab” data from an external source. If the external source updates the data, then our next API call with obtain the updated data.\nFor example, let’s say we wanted to obtain data from FRED on real Gross Domestic Product (GDP) for the United States from 1980 to the most current data available. We could go to FRED, search for real GDP, find the real GDP variable is called GDPC1, and download the data into an Excel file. This process is labor-intensive and subject to error.\nFRED: https://fred.stlouisfed.org/\nReal GDP: https://fred.stlouisfed.org/series/GDPC1\nWe can use an API call to obtain the data. Instead of having to write the code for an API call, we can use a package called tidyquant.\nWe have the variable name GDPC1 and so we can simply use the tq_get function in tidyquant to retrieve the real GDP series.\nWe rename the price variable to rgdp and we convert the date using the lubridate package.\nWe can use the head or kable to print out the contents of the first rows of the resulting data frame.\nWe see the data are organized such that each row corresponds to a time period, that is, the first row represents real GDP for the 1st quarter of 1950, the second row represents real GDP for the 2nd quarter of 1950, and so on.\n\nrm(list = ls())\n\n#Load packages\n\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(tidyverse)\nlibrary(kableExtra)\nlibrary(tidyquant)\n\n#Use tq_get to obtain real GDP from FRED\n\nrgdp &lt;- tq_get(\"GDPC1\",\n                    get  = \"economic.data\",\n                    from = \"1950-01-01\" ) %&gt;%\n        rename(rgdp = price) %&gt;%\n        mutate(date = lubridate::ymd(date))\n\nkable(rgdp[1:5,]) %&gt;%\n  kable_classic()\n\n\n\n\nsymbol\ndate\nrgdp\n\n\n\n\nGDPC1\n1950-01-01\n2346.104\n\n\nGDPC1\n1950-04-01\n2417.682\n\n\nGDPC1\n1950-07-01\n2511.127\n\n\nGDPC1\n1950-10-01\n2559.214\n\n\nGDPC1\n1951-01-01\n2593.967",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data frames in R</span>"
    ]
  },
  {
    "objectID": "mod-1-4-intro-to-r-dataframes.html#the-fred-api-for-nominal-gdp",
    "href": "mod-1-4-intro-to-r-dataframes.html#the-fred-api-for-nominal-gdp",
    "title": "8  Data frames in R",
    "section": "8.8 The FRED API for Nominal GDP",
    "text": "8.8 The FRED API for Nominal GDP\nWe can also make an API call to FRED for the nominal GDP series. Much like the real GDP API call, we have a data frame with the price variable containing the values for nominal GDP. We rename the variable to gdp and also use the lubridate package for the dates.\nNominal GDP: https://fred.stlouisfed.org/series/GDP\n\nrm(list = ls())\n\n#Load packages\n\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(tidyverse)\nlibrary(kableExtra)\nlibrary(tidyquant)\n\n#Use tq_get to obtain nominal GDP from FRED\n\ngdp &lt;- tq_get(\"GDP\",\n                    get  = \"economic.data\",\n                    from = \"1950-01-01\" ) %&gt;%\n        rename(gdp = price) %&gt;%\n        mutate(date = lubridate::ymd(date))\n\nkable(gdp[1:5,]) %&gt;%\n  kable_classic()\n\n\n\n\nsymbol\ndate\ngdp\n\n\n\n\nGDP\n1950-01-01\n280.828\n\n\nGDP\n1950-04-01\n290.383\n\n\nGDP\n1950-07-01\n308.153\n\n\nGDP\n1950-10-01\n319.945\n\n\nGDP\n1951-01-01\n336.000",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data frames in R</span>"
    ]
  },
  {
    "objectID": "mod-1-4-intro-to-r-dataframes.html#the-fred-api-for-nominal-and-real-gdp",
    "href": "mod-1-4-intro-to-r-dataframes.html#the-fred-api-for-nominal-and-real-gdp",
    "title": "8  Data frames in R",
    "section": "8.9 The FRED API for Nominal and Real GDP",
    "text": "8.9 The FRED API for Nominal and Real GDP\nIn the previous examples, we made an API call for one variable at a time. The result was two data frames, one for nominal GDP, and one for real GDP. It would be more efficient to make one API call that results in a single data frame with both variables.\nIn the following code, we combine the names of the two variables, that is, c(“GDP”,“GDPC1”) creates a row vector with the two names. This row vector is used by the tq_get function to make an API call to obtain the two variables from FRED.\nWhat’s important to note is that the all_gdp data fame is in long format. In other words, each row corresponds to one period of time for one variable.\nWe have to do some housecleaning. When we obtain the data from FRED, the variable names are contained in a variable called symbol and the values are contained in a variable named price. We rename those to variable and value, respectively.\nWe then plot the data using the ggplot2 package.\nThe ggplot function is very flexible and you can modify almost every element of a graph. For now, we provide the example and will work on developing our graphing skills later on in the course.\n\nrm(list = ls())\n\n#Load packages\n\nlibrary(dplyr)\nlibrary(kableExtra)\nlibrary(lubridate)\nlibrary(tidyquant)\nlibrary(tidyverse)\nlibrary(ggplot2)\n\n#Use tq_get to obtain nominal and real GDP from FRED\n\nall_gdp &lt;- tq_get(c(\"GDP\", \"GDPC1\"), \n                  get  = \"economic.data\",\n                    from = \"1950-01-01\") %&gt;%\n        mutate(date     = lubridate::ymd(date)) %&gt;%\n        rename(variable = symbol,\n               value    = price)\n\n# Produce Table of First 10 Observations\n\nkable(all_gdp[1:10,],\n      col.names = c(\"Variable\",\n                    \"Date\",\n                    \"Value\"))\n\n\n\nVariable\nDate\nValue\n\n\n\n\nGDP\n1950-01-01\n280.828\n\n\nGDP\n1950-04-01\n290.383\n\n\nGDP\n1950-07-01\n308.153\n\n\nGDP\n1950-10-01\n319.945\n\n\nGDP\n1951-01-01\n336.000\n\n\nGDP\n1951-04-01\n344.090\n\n\nGDP\n1951-07-01\n351.385\n\n\nGDP\n1951-10-01\n356.178\n\n\nGDP\n1952-01-01\n359.820\n\n\nGDP\n1952-04-01\n361.030\n\n\n\n#Use GGPLOT \n#GDP over time\n\nggplot(data = all_gdp, \n       aes(x = date, \n           y = value,\n           color = variable,\n           group = variable)) +\ngeom_line(linewidth = 1) +\nscale_y_continuous(labels = scales::dollar_format()) +\ntheme_minimal() +\ntheme(legend.position = 'bottom',\n      legend.title    = element_blank()) +\nlabs(title    = \"Real and Nominal GDP, United States\",\n     subtitle = \"Billions of Dollars\",\n     x        = \"Date\",\n     y        = \"Billions of Dollars\")",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data frames in R</span>"
    ]
  },
  {
    "objectID": "mod-1-5-quarto.html",
    "href": "mod-1-5-quarto.html",
    "title": "9  Using Quarto",
    "section": "",
    "text": "9.1 What is Quarto?\nQuatro is how we will work with R and RStudio to produce documents, assignments, and exams.\nOne way to think about Quarto is that it is like Microsoft Word, however, it is much more powerful and flexible.\nIn fact, the entire ECON 700 course is built with R, RStudio, and Quarto.\nAs with R and RStudio, the more you work with Quarto, the easier it comes to work with Quarto.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Using Quarto</span>"
    ]
  },
  {
    "objectID": "mod-1-5-quarto.html#getting-started",
    "href": "mod-1-5-quarto.html#getting-started",
    "title": "9  Using Quarto",
    "section": "9.2 Getting Started",
    "text": "9.2 Getting Started\nTo get started with Quarto, you have to install Quarto.\nThis step assumes you have already installed R and RStudio.\nTo install Quarto, go to https://quarto.org/docs/get-started/\n\n\n\nQuarto Installation Page\n\n\nOnce you have installed Quarto, go to the getting started in RStudio page.\nYou can find this page at: https://quarto.org/docs/get-started/hello/rstudio.html\nThe getting started page will help you understand the capabilities of Quarto.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Using Quarto</span>"
    ]
  },
  {
    "objectID": "mod-1-5-quarto.html#creating-a-file",
    "href": "mod-1-5-quarto.html#creating-a-file",
    "title": "9  Using Quarto",
    "section": "9.3 Creating a File",
    "text": "9.3 Creating a File\nIn RStudio, go to File -&gt; New File -&gt; New Quatro Document.\nYou will see the window below. Let’s say we name our document: Example-1.\n\nOnce you have created this file, you will see the following window in RStudio:\n\n\n\nScreenshot of New Quarto Document",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Using Quarto</span>"
    ]
  },
  {
    "objectID": "mod-1-5-quarto.html#code-chunks",
    "href": "mod-1-5-quarto.html#code-chunks",
    "title": "9  Using Quarto",
    "section": "9.4 Code Chunks",
    "text": "9.4 Code Chunks\nR code chunks can be identified with {r}.\nTo start a code chunk, you use ```{r} and you close off the code chunk with ```.\nYou can run the code chunk interactively in RStudio, that is, you can click on the green arrow icon at the top of the code chunk and RStudio will display the results.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Using Quarto</span>"
    ]
  },
  {
    "objectID": "mod-1-5-quarto.html#working-with-quartro",
    "href": "mod-1-5-quarto.html#working-with-quartro",
    "title": "9  Using Quarto",
    "section": "9.5 Working with Quartro",
    "text": "9.5 Working with Quartro\nWe want to create a text description of in our new Quarto document. We also want to create a simple code chunk in our Quarto document that will execute when we render our file.\nIn your new file, let’s write the following text:\nThis is an example Quarto file. You can write text here like a normal document.\nAnd let’s include the following code chunk:\n\nx &lt;- 3\ny &lt;- 6\nz &lt;- 10\n\nx*y\ny*z\nx/z\n\nYour file should look like the following picture:\n\n\n\nScreenshot of Quarto Example Document",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Using Quarto</span>"
    ]
  },
  {
    "objectID": "mod-1-5-quarto.html#rendering",
    "href": "mod-1-5-quarto.html#rendering",
    "title": "9  Using Quarto",
    "section": "9.6 Rendering",
    "text": "9.6 Rendering\nUse the Render button in RStudio to render the file and previous the output. If you prefer to automatically render whenever you save, check the Render on Save button in RStudio.\nWhen you render, your can save your file as Example1.qmd and the rendered file should appear in a browser window.\nQuarto is a powerful approach to displaying your work in R and RStudio.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Using Quarto</span>"
    ]
  },
  {
    "objectID": "mod-1-5-quarto.html#additional-resources",
    "href": "mod-1-5-quarto.html#additional-resources",
    "title": "9  Using Quarto",
    "section": "9.7 Additional Resources",
    "text": "9.7 Additional Resources\nGetting started with Quarto video from Posit: https://youtu.be/_f3latmOhew?si=FS-Ue1--z-hLGtKg\nQuarto crash course: https://www.youtube.com/watch?v=oYV1a9sWhgM\nR for Data Science: Quarto https://r4ds.hadley.nz/quarto.html\nIntroduction to Quarto, Klajdi Puka: https://kpuka.ca/resources/quarto_intro.html",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Using Quarto</span>"
    ]
  },
  {
    "objectID": "mod-2-0-overview.html",
    "href": "mod-2-0-overview.html",
    "title": "10  Module 2 Overview",
    "section": "",
    "text": "10.1 Introduction\nWelcome to Module 2 of ECON 700.\nIn this module, you will deepen your understanding of how to summarize and interpret data using descriptive statistics. You will learn to organize data into frequency and relative frequency distributions, calculate measures that describe the center and spread of data, and assess how individual observations compare to the overall dataset.\nEmphasis will be placed on using R to compute and visualize descriptive statistics, including the mean, median, mode, range, variance, standard deviation, coefficient of variation, and z-scores. By the end of this module, you will be able to use these tools to describe key features of economic data accurately and communicate your findings effectively through reproducible R-based analyses.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Module 2 Overview</span>"
    ]
  },
  {
    "objectID": "mod-2-0-overview.html#learning-objectives",
    "href": "mod-2-0-overview.html#learning-objectives",
    "title": "10  Module 2 Overview",
    "section": "10.2 Learning Objectives",
    "text": "10.2 Learning Objectives\nBy the end of this module, you should be able to:\n\nConstruct and interpret frequency and relative frequency distributions to summarize quantitative data.\nCompute and interpret measures of central tendency, including the mean, median, mode, and trimmed and weighted means.\nCalculate and explain measures of variability, including the range, variance, standard deviation, and coefficient of variation.\nUse z-scores to assess relative position and identify outliers within a dataset.\nApply R to generate, visualize, and interpret descriptive statistics and graphical summaries of economic data.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Module 2 Overview</span>"
    ]
  },
  {
    "objectID": "mod-2-0-overview.html#readings-resources",
    "href": "mod-2-0-overview.html#readings-resources",
    "title": "10  Module 2 Overview",
    "section": "10.3 Readings & Resources",
    "text": "10.3 Readings & Resources\n\nBarbara Illowsky and Susan Dean. Introductory Statistics 2e. OpenStax. (Chapter 2). Available for free online at https://openstax.org/books/introductory-statistics-2e/pages/2-introduction\nIrizarry, R. (2025). Introduction to Data Science: Data Wrangling and Visualization with R. (Chapters 1-2). Available for free at: https://rafalab.dfci.harvard.edu/dsbook-part-1/\nWickham, H., & Grolemund, G. (2017). R for Data Science. (Chapters 1–3).\n\nOnline R documentation: https://cran.r-project.org/manuals.html\n\nRStudio Cheat Sheets",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Module 2 Overview</span>"
    ]
  },
  {
    "objectID": "mod-2-0-overview.html#activities",
    "href": "mod-2-0-overview.html#activities",
    "title": "10  Module 2 Overview",
    "section": "10.4 Activities",
    "text": "10.4 Activities\n\nComplete the hands-on coding exercises embedded in each lesson.\n\nComplete the weekly class assignment.\n\nParticipate in the discussion form.\n\nTake the weekly knowledge quiz.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Module 2 Overview</span>"
    ]
  },
  {
    "objectID": "mod-2-0-overview.html#lessons-in-this-module",
    "href": "mod-2-0-overview.html#lessons-in-this-module",
    "title": "10  Module 2 Overview",
    "section": "10.5 Lessons in this Module",
    "text": "10.5 Lessons in this Module\n\n2.1 – Frequency Distributions\n\n2.2 - Measures of Central Tendency\n2.3 - Measures of Dispersion\n\n\nNext: Start with Frequency Distributions.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Module 2 Overview</span>"
    ]
  },
  {
    "objectID": "mod-2-1-frequency.html",
    "href": "mod-2-1-frequency.html",
    "title": "11  Frequency Distributions",
    "section": "",
    "text": "11.1 Frequency Distributions\nThe frequency of a category, class, or value is the number of times it occurs in a data set.\nA frequency distribution is summary of data.\nA frequency distribution is the pattern of frequencies of variable of interest.\nGiven several non-overlapping categories or classes, a frequency distribution contains the number of observations per class or category.\nA frequency distribution, to be complete, must be:\nA frequency distribution may provide insights about the data that cannot be quickly obtained by examining the data itself.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Frequency Distributions</span>"
    ]
  },
  {
    "objectID": "mod-2-1-frequency.html#frequency-distributions",
    "href": "mod-2-1-frequency.html#frequency-distributions",
    "title": "11  Frequency Distributions",
    "section": "",
    "text": "Mutually exclusive - the classes or categories do not overlap.\nCollectively exhaustive - all the observations are described by the distribution",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Frequency Distributions</span>"
    ]
  },
  {
    "objectID": "mod-2-1-frequency.html#frequency-example",
    "href": "mod-2-1-frequency.html#frequency-example",
    "title": "11  Frequency Distributions",
    "section": "11.2 Frequency Example",
    "text": "11.2 Frequency Example\nIn the example below, we have six observations (students).\nThe students can be grouped by their graduating year. There are 3 students that graduate in 2028 and 4 students that graduate in 2029.\nThe number of students for each group is the frequency (count) associated with the group, that is,\n\nGraduating Year 2028: 3\nGraduating Year 2029: 4\n\n\nTable of Observations\n\n\nStudent\nGraduating Year\nGrade Point Average\n\n\n\n\n1\n2028\n3.0\n\n\n2\n2028\n2.8\n\n\n3\n2028\n3.5\n\n\n4\n2029\n2.7\n\n\n5\n2029\n2.8\n\n\n6\n2029\n3.0\n\n\n7\n2029\n3.6",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Frequency Distributions</span>"
    ]
  },
  {
    "objectID": "mod-2-1-frequency.html#mtcars-frequency",
    "href": "mod-2-1-frequency.html#mtcars-frequency",
    "title": "11  Frequency Distributions",
    "section": "11.3 Mtcars Frequency",
    "text": "11.3 Mtcars Frequency\nFor the following example, we use the mtcars data frame.\nFirst, we group the data by the cylinder variable. The group_by function notifies R that the data are organized by a specific variable or variables.\nHere, we notify R that the cylinder variable is how the data are grouped together, that is, R should consider all the observations with 4 cylinders one group, all the observations with 6 cylinders one group, and all the observations with 8 cylinders one group.\nSecond, we create a new variable freq_cyl using the summarize function. The variable freq_cyl is equal to the number of observations in each group.\nWe then use the arrange function to sort the resulting frequencies from lowest number to the highest number.\nWe create a frequency table using the kable function.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Frequency Distributions</span>"
    ]
  },
  {
    "objectID": "mod-2-1-frequency.html#census-frequency",
    "href": "mod-2-1-frequency.html#census-frequency",
    "title": "11  Frequency Distributions",
    "section": "11.4 Census Frequency",
    "text": "11.4 Census Frequency\nIn the example below, we use the censusapi package to obtain data from the U.S. Census Bureau’s American Community Survey.\nWe use the API to download data on counties and county-equivalent geographies for the United States. We specify two variables, the name of each geography and the population of each geography.\nWe rename the census population variable, B01001_001E, to total_pop.\nWe want to create categories for different ranges of population. To do this, we use the case_when function.\nHaving created the population categories, we group_by the population category variable and then use the summarize function to obtain a count of the number of observations in each category.\n\n# Clear Memory \nrm(list = ls())\n\n# Load Libraries\n\nlibrary(censusapi)\nlibrary(dplyr)\nlibrary(kableExtra)\nlibrary(tidyverse)\n\n#B01001_001E is total population\n#Case When to Create Categories\n\ncounty_pop &lt;- getCensus(name = \"acs/acs5\",\n            vintage = 2023,\n            key = \"9c1637a56ff93f0af6b4b1d0547ea048fe668175\",\n            vars = c(\"NAME\",\n                     \"B01001_001E\"),\n            region = \"county:*\") %&gt;%\nrename(total_pop = B01001_001E) %&gt;%\nmutate(pop_cat = case_when(total_pop &gt; 99999 ~ \"Greater than 99,999\",\n                           total_pop &gt; 49999 ~ \"50,000 - 99,999\",\n                           total_pop &gt; 24999 ~ \"25,000 - 49,999\",\n                           total_pop &gt; 9999  ~ \"10,000 - 24,999\",\n                           TRUE ~ \"0 - 9,999\"))\n\n# Summarize to Create Frequencies by Categories\n\ncounty_freq &lt;- county_pop %&gt;%\n  group_by(pop_cat) %&gt;%\n  summarize(freq_pop = n()) %&gt;%\n  arrange(pop_cat)\n\n# Use frequency data frame to produce table\n\nkable(county_freq,\n      col.names = c(\"Category\", \"Frequency\"),\n      align = c('c','c'),\n      caption = 'Frequency of County Population, 2023') %&gt;%\nkable_styling(font_size = 14)\n\n\nFrequency of County Population, 2023\n\n\nCategory\nFrequency\n\n\n\n\n0 - 9,999\n743\n\n\n10,000 - 24,999\n823\n\n\n25,000 - 49,999\n643\n\n\n50,000 - 99,999\n397\n\n\nGreater than 99,999\n616",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Frequency Distributions</span>"
    ]
  },
  {
    "objectID": "mod-2-1-frequency.html#frequency-distributions-1",
    "href": "mod-2-1-frequency.html#frequency-distributions-1",
    "title": "11  Frequency Distributions",
    "section": "11.5 Frequency Distributions",
    "text": "11.5 Frequency Distributions\nWe can graphically depict the frequency distribution.\nWe use the ggplot package to create a graphical plot of the frequency distribution.\nTo learn more about the capabilities of ggplot, see https://ggplot2.tidyverse.org/.\nWe have categories (population size) on the x-axis and the frequencies on the y-axis.\nWe use the geom_col command to create a column chart of the frequencies. We choose to fill the columns with the darkblue color.\nThe labs command specifies the labels for the plot, to include the x-axis, y-axis, title, and subtitle.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Frequency Distributions</span>"
    ]
  },
  {
    "objectID": "mod-2-1-frequency.html#relative-frequency-distributions",
    "href": "mod-2-1-frequency.html#relative-frequency-distributions",
    "title": "11  Frequency Distributions",
    "section": "11.6 Relative Frequency Distributions",
    "text": "11.6 Relative Frequency Distributions\nThe frequency distribution may not be as informative as we would like if the number of observations is sufficiently large.\nIn the frequency distribution for the population of U.S. counties, there were more than 600 counties with populations between 10,000 and 24,999 individuals. How does this compare with the number of counties with populations less than 10,000?\nA relative frequency distribution contains information on the proportion of observations in each class relative to the total number of observations.\nLet \\(n\\) be the total number of observations.\nLet \\(i\\) represent the number of classes or categories.\nLet \\(n_i\\) be the total number of observations in the i-th class.\n\\[\\text{Relative Frequency of Class}_i = \\frac{n_i}{n}\\]",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Frequency Distributions</span>"
    ]
  },
  {
    "objectID": "mod-2-1-frequency.html#relative-frequency-mtcars",
    "href": "mod-2-1-frequency.html#relative-frequency-mtcars",
    "title": "11  Frequency Distributions",
    "section": "11.7 Relative Frequency: Mtcars",
    "text": "11.7 Relative Frequency: Mtcars\nWe use the mtcars example data.\nWe group the data by the cylinder variable.\nWe estimate the frequency by cylinder.\nWe estimate the relative frequency using the mutate function.\nWe create a frequency table using the kable function.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Frequency Distributions</span>"
    ]
  },
  {
    "objectID": "mod-2-1-frequency.html#relative-frequency-census",
    "href": "mod-2-1-frequency.html#relative-frequency-census",
    "title": "11  Frequency Distributions",
    "section": "11.8 Relative Frequency: Census",
    "text": "11.8 Relative Frequency: Census\nWe can also graphically depict the frequency distribution.\nWe return to our previous example using data from the U.S. Census Bureau. We obtain data on population for counties and county-equivalent geographies in the United States.\nWe use case_when to create a categorical variable that groups geographies into population bins.\nAs before, we use summarize to count the number of observations in each bin.\nWe then estimate the relative frequency by diving the number of observations in each bin by the total number of observations or\n\\[\\text{Relative Frequency of Population Bin}_i = \\frac{\\text{Observations in Bin}_i}{\\text{Total Observations}}\\]\nIn other words, the relative frequency of the 0 to 9,999 population bin is equal to the number of counties in that bin divided by the total number of counties across all bins.\nWe then ggplot to create a graphical plot of the frequency distribution.\nWe have categories (population size) on the x-axis and the frequencies on the y-axis.\n\nrm(list = ls())\n\nlibrary(censusapi)\nlibrary(dplyr)\nlibrary(kableExtra)\nlibrary(tidyverse)\n\n#B01001_001E is total population\n#Case When to Create Categories\n\ncounty_pop &lt;- getCensus(name = \"acs/acs5\",\n            vintage = 2023,\n            key = \"9c1637a56ff93f0af6b4b1d0547ea048fe668175\",\n            vars = c(\"NAME\",\n                     \"B01001_001E\"),\n            region = \"county:*\") %&gt;%\nrename(total_pop = B01001_001E) %&gt;%\nmutate(pop_cat = case_when(total_pop &gt; 99999 ~ \"Greater than 99,999\",\n                           total_pop &gt; 49999 ~ \"50,000 - 99,999\",\n                           total_pop &gt; 24999 ~ \"25,000 - 49,999\",\n                           total_pop &gt; 9999  ~ \"10,000 - 24,999\",\n                           TRUE ~ \"0 - 9,999\"))\n\ncounty_freq &lt;- county_pop %&gt;%\n  group_by(pop_cat) %&gt;%\n  summarize(freq_pop = n()) %&gt;%\n  mutate(rel_freq = freq_pop/sum(freq_pop)) %&gt;%\n  arrange(pop_cat)\n\nggplot(data = county_freq,\n       aes(x = pop_cat,\n           y = rel_freq,\n           fill = rel_freq)) +\ngeom_col() +\ntheme_minimal() +\ntheme(legend.position=\"none\") +\nlabs(title = \"Relative Frequency of Population Bins\",\n     x     = \"Population Bin\",\n     y     = \"Relative Frequency\")",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Frequency Distributions</span>"
    ]
  },
  {
    "objectID": "mod-2-1-frequency.html#scatterplots",
    "href": "mod-2-1-frequency.html#scatterplots",
    "title": "11  Frequency Distributions",
    "section": "11.9 Scatterplots",
    "text": "11.9 Scatterplots\nA scatterplot is a graphical display of a relationship between two variables of interest.\nBefore constructing a scatterplot, one must think about the nature of the relationship between the two variables.\nThe independent variable is typically represented on the horizontal axis while the dependent variable is typically represented on the vertical axis.\nThe hypothesized relationship between the \\(x\\) and \\(y\\) variables can be expressed as:\n\\[y = f(x)\\]\nCare must be taken to avoid interpreting the visual relationship.\nIn other words, what if the true relationship is:\n\\[y = f(x, w, z)\\]\nIf you plot \\(y\\) and \\(x\\) and interpret the visual relationship, you are ignoring the potential relationships between \\(y\\) and \\(w\\) and \\(y\\) and \\(z\\).\nScatterplots may inform, but we should always be careful with any conclusions we derive from merely observing the pattern of two variables.\nIn the code below, we plot weight in pounds on the x-axis and miles per gallon on the y-axis. It would seem that there is a negative relationship between the weight of cars and their fuel efficiency. Heavier cars appear to have lower fuel efficiency.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Frequency Distributions</span>"
    ]
  },
  {
    "objectID": "mod-2-2-central.html",
    "href": "mod-2-2-central.html",
    "title": "12  Central Tendency",
    "section": "",
    "text": "12.1 Data Properties\nThe properties of a set of data can be described (in general) by:\nThe center of the data refers to the measure of central tendency of the data, that is, what is an estimate of the “middle” of the data.\nThe spread of the data refers to how “far apart” observations are in the data relative to center of the data.\nThere are two typical measures of the shape of the data:\nThe measures of the center, spread, and shape of the data help us understand the properties of the data.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Central Tendency</span>"
    ]
  },
  {
    "objectID": "mod-2-2-central.html#data-properties",
    "href": "mod-2-2-central.html#data-properties",
    "title": "12  Central Tendency",
    "section": "",
    "text": "The center of the data.\nThe spread of the data.\nThe shape of the data\n\n\n\n\n\nAre the data symmetrically or asymmetrically distributed around the mean?\nAre the data concentrated in one tail of the distribution?",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Central Tendency</span>"
    ]
  },
  {
    "objectID": "mod-2-2-central.html#population-mean-and-sample-average",
    "href": "mod-2-2-central.html#population-mean-and-sample-average",
    "title": "12  Central Tendency",
    "section": "12.2 Population Mean and Sample Average",
    "text": "12.2 Population Mean and Sample Average\nRecall that population data is comprehensive information collected on all members of a group or entity under study. The population is the universe of members of the group.\nRecall that sample data is a subset of the population data. Samples may range from 1 member of the population of interest to many members of a population of interest.\nLet \\(N\\) be the number of members of a specified group.\n\\(N\\) defines the size of the population of the group of interest.\nLet \\(n = N - j\\) where \\(0 \\le j \\le N\\).\n\\(n\\) is the size of a sample of the population size \\(N\\).\nGiven a population size \\(N\\), the population mean, \\(\\mu\\), is defined as:\n\\[\\mu = \\frac{1}{N} \\sum_{i = 1}^N x_i\\]\nFor a sample size \\(n\\) from a population size \\(N\\), then the sample average \\(\\bar{X}\\) is:\n\\[\\bar{x} = \\frac{1}{n} \\sum_{i = 1}^n x_i\\] Here we must be careful in our use of language. When we say mean we refer to the population mean, that is, the mean obtained using all the members of the population. When we say sample, we refer to the sample average, that is, the average obtained using a subset of the members of the population.\nIn the example below, we can use the summarize function to determine number of observations, the minimum value for mpg, the maximum value for mpg, and the sample average for mpg.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Central Tendency</span>"
    ]
  },
  {
    "objectID": "mod-2-2-central.html#mean-and-median",
    "href": "mod-2-2-central.html#mean-and-median",
    "title": "12  Central Tendency",
    "section": "12.3 Mean and Median",
    "text": "12.3 Mean and Median\nThe population mean, \\(\\mu\\), is one measure of the center of the data.\nThe population median is another measure of the center of the data.\nThe median is a value that separates the observations in half.\nFor a given median, 50% of the observations are below the median value and 50% of the observations are above the median value.Depending on the spread and shape of the data, the mean and median may be relatively close or far apart.\nOutlying observations can “pull” the mean far from the “center” of the data.\nIn the example below, we use the censusapi package to access the U.S. Census API to obtain data on total population for county and county-equivalent geographies.\nNote the difference between the mtcars example and the census example: the mtcars example is a sample while the census examine uses population data.\nWe then estimate the following descriptive statistics for the population of geographies:\n\nNumber of observations\nMinimum value for population\nMaximum value for population\nMedian value for population\nMean value for population\n\n\nrm(list = ls())\n\nlibrary(censusapi)\nlibrary(dplyr)\nlibrary(kableExtra)\nlibrary(tidyverse)\n\ncounty_pop &lt;- getCensus(name = \"acs/acs5\",\n            vintage = 2023,\n            key = \"9c1637a56ff93f0af6b4b1d0547ea048fe668175\",\n            vars = c(\"NAME\",\n                     \"B01001_001E\"),\n            region = \"county:*\") %&gt;%\nrename(pop = B01001_001E) %&gt;%\nsummarize(n_pop    = n(),\n          min_pop  = min(pop),\n          max_pop  = max(pop),\n          med_pop  = median(pop),\n          mean_pop = mean(pop))\n\nkable(county_pop,\n      col.names = c(\"N\", \"Minimum\", \"Maximum\",\n                    \"Median\", \"Mean\"),\n      align     = 'c',\n      format.args = list(big.mark = \",\"),\n      caption = 'Descriptive Statistics of U.S. Counties - Population') %&gt;%\nkable_styling(font_size = 12)\n\n\nDescriptive Statistics of U.S. Counties - Population\n\n\nN\nMinimum\nMaximum\nMedian\nMean\n\n\n\n\n3,222\n43\n9,848,406\n25,967\n104,172.1",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Central Tendency</span>"
    ]
  },
  {
    "objectID": "mod-2-2-central.html#mean-deviations",
    "href": "mod-2-2-central.html#mean-deviations",
    "title": "12  Central Tendency",
    "section": "12.4 Mean Deviations",
    "text": "12.4 Mean Deviations\nWe have estimated the population mean (\\(\\mu\\)) and the sample average (\\(\\bar{x}\\)).\nWe can now construct an estimate of how much each observation deviates from the population mean or sample average.\nGiven the i-th observation for a variable \\(x\\), that is, \\(x_i\\), the mean deviation of \\(x_i\\) is:\n\\[d_i = x_i - \\mu\\] Given the i-th observation for a variable \\(x\\), that is, \\(x_i\\), the average deviation of \\(x_i\\) for a sample is:\n\\[d_i = x_i - \\bar{x}\\]\nThe sum of the mean deviations is zero for the population or approximately zero for a sample.\n\\[\\sum_{i = 1}^N d_i = \\sum_{i = 1}^N (x_i - \\mu) = 0\\]\n\\[\\sum_{i = 1}^N d_i = \\sum_{i = 1}^N (x_i - \\bar{x}) \\approx 0\\]",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Central Tendency</span>"
    ]
  },
  {
    "objectID": "mod-2-2-central.html#mean-deviations-example",
    "href": "mod-2-2-central.html#mean-deviations-example",
    "title": "12  Central Tendency",
    "section": "12.5 Mean Deviations Example",
    "text": "12.5 Mean Deviations Example\nIn the example below, we estimate the sample average deviation for the mtcars example. We select the miles per gallon variable, estimate the sample average, and then estimate the average deviation for every observation in the sample.\nWe then output the first five observations to illustrate the estimation of average deviations.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nIn this example, we select two variables: miles per gallon and weight.\nWe estimate the sample average for both variables. We then sum the average deviations for each variable.\nThe table illustrates, that for the sample, the sum of the average deviations is approximately zero for each of the variables.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Central Tendency</span>"
    ]
  },
  {
    "objectID": "mod-2-2-central.html#trimmed-mean",
    "href": "mod-2-2-central.html#trimmed-mean",
    "title": "12  Central Tendency",
    "section": "12.6 Trimmed Mean",
    "text": "12.6 Trimmed Mean\nThe U.S. Census population data illustrates how an outlying observation (Los Angeles County) can ‘pull’ the population mean away from the “center” of the data.\nWe can trim the data to account for the presence of outliers.\nTrimming the data is a transformation of the data\nIn most cases, 5% to 25% of the data from the ends of the distribution are discarded to estimate the trimmed mean.\nThe median is a fully truncated mean, that is, the median represents the discard of 50% of the observations from each end of the distribution.\nThe trimmed mean is less sensitive to outliers and will provide a “reasonable” estimate of the population mean in many cases.\nRemoving the highest and lowest scores in a competition to obtained a trimmed mean makes the resulting score more robust to outliers.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Central Tendency</span>"
    ]
  },
  {
    "objectID": "mod-2-2-central.html#trimmed-mean-example",
    "href": "mod-2-2-central.html#trimmed-mean-example",
    "title": "12  Central Tendency",
    "section": "12.7 Trimmed Mean Example",
    "text": "12.7 Trimmed Mean Example\nWe estimate the number of observations, minimum and maximum values, and mean and median for population for all U.S. counties using the data from the U.S. Census.\nWe note that several large counties “pull” the mean population away from the median population.\nWe can estimate the trimmed mean using the mean function with the trim option.\nThe trimmed mean removes a specified percentage of the smallest and largest values from a dataset to reduce the impact of outliers.\nNote how even with a 5% trim, the mean of the remaining observations quickly approaches the population mean.\nNote how the 50% trim results in the population mean.\n\nrm(list = ls())\n\nlibrary(censusapi)\nlibrary(dplyr)\nlibrary(kableExtra)\nlibrary(tidyverse)\n\ncounty_pop &lt;- getCensus(name = \"acs/acs5\",\n            vintage = 2023,\n            key = \"9c1637a56ff93f0af6b4b1d0547ea048fe668175\",\n            vars = c(\"NAME\",\n                     \"B01001_001E\"),\n            region = \"county:*\") %&gt;%\nrename(pop = B01001_001E) %&gt;%\nsummarize(med_pop  = median(pop),\n          mean_pop = mean(pop),\n          mean_05  = mean(pop, trim = 0.05),\n          mean_10  = mean(pop, trim = 0.10),\n          mean_20  = mean(pop, trim = 0.20),\n          mean_50  = mean(pop, trim = 0.50))\n\nkable(county_pop,\n      col.names = c('Median', 'Mean',\n                    'Trim 0.05', 'Trim 0.10',\n                    'Trim 0.20', 'Trim 0.50'),\n      align     = 'c',\n      digits    = 2,\n      caption = 'Mean and Trimmed Means, County Population') %&gt;%\nkable_styling(font_size = 12)\n\n\nMean and Trimmed Means, County Population\n\n\nMedian\nMean\nTrim 0.05\nTrim 0.10\nTrim 0.20\nTrim 0.50\n\n\n\n\n25967\n104172.1\n55627.37\n42982.97\n32445.04\n25967",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Central Tendency</span>"
    ]
  },
  {
    "objectID": "mod-2-2-central.html#weighted-mean",
    "href": "mod-2-2-central.html#weighted-mean",
    "title": "12  Central Tendency",
    "section": "12.8 Weighted Mean",
    "text": "12.8 Weighted Mean\nGiven \\(N\\) observations of \\(x\\) and weights \\(w_i\\), the weighted population mean, \\(\\mu_w\\), is\n\\[\\mu_w = \\sum_{i = 1}^N w_i \\times x_i\\]\nFor the population mean, \\(\\mu\\), the weights are equal to \\(1/N\\) or\n\\[\\mu = \\frac{1}{N} \\sum_{i = 1}^N = \\frac{1}{N}x_1 + \\frac{1}{N}x_2 + \\dots + \\frac{1}{N}x_N\\]\nGiven \\(n\\) observations of \\(x\\), the weighted sampel average \\(\\bar{x}_w\\), is defined as:\n\\[\\bar{x}_w = \\sum_{i = 1}^n w_i \\times x_i\\]\nFor the sample average, \\(\\bar{x}\\), the weights are equal to \\(1/n\\) or\n\\[\\bar{x} = \\frac{1}{n} \\sum_{i = 1}^n = \\frac{1}{n}x_1 + \\frac{1}{n}x_2 + \\dots + \\frac{1}{n}x_n\\]",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Central Tendency</span>"
    ]
  },
  {
    "objectID": "mod-2-2-central.html#weighted-mean-example",
    "href": "mod-2-2-central.html#weighted-mean-example",
    "title": "12  Central Tendency",
    "section": "12.9 Weighted Mean Example",
    "text": "12.9 Weighted Mean Example\nLet’s create a data frame with three variables\nLet x be a vector of squares\nLet wt_1 be a vector of equal weights.\nLet wt_2 be a vector of unequal weights\nWe estimate the mean using the mean function and the weighted mean using the weighted.mean function\nAs expected, using equal weights returns the same value as the mean function.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Central Tendency</span>"
    ]
  },
  {
    "objectID": "mod-2-2-central.html#quantiles-and-percentiles",
    "href": "mod-2-2-central.html#quantiles-and-percentiles",
    "title": "12  Central Tendency",
    "section": "12.10 Quantiles and Percentiles",
    "text": "12.10 Quantiles and Percentiles\nLet the p-th quantile be the value in the data for which \\(100 \\times p\\) of the data are less than the value.\nA percentile is the same concept as the quantile but the range is 0 to 100.\nA quantile refers to the 0, 25, 50, 75, and 100 percentiles.\nA quintile refers to the 0, 20, 40, 60, 80, and 100 percentiles.\nA decile refers to the 0, 10, 20, 30, 40, 50, 60, 70, 80, 90, and 100 percentiles.\nGiven sorted data, the p-th quantile is at position\n\\[1 + p \\times (n+1)\\]\nIf you want to determine the location of the p-th percent,\n\\[L_p = \\frac{p}{100} \\times (n+1)\\]",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Central Tendency</span>"
    ]
  },
  {
    "objectID": "mod-2-2-central.html#quantiles-and-percentiles-example",
    "href": "mod-2-2-central.html#quantiles-and-percentiles-example",
    "title": "12  Central Tendency",
    "section": "12.11 Quantiles and Percentiles Example",
    "text": "12.11 Quantiles and Percentiles Example\n\nClears the environment:\n\nRemoves all objects from memory using rm(list = ls()) to ensure a clean workspace.\n\nLoads the mtcars dataset:\n\nUses the built-in R dataset containing car performance data such as miles per gallon, cylinders, and weight.\n\nCalculates quantiles for selected variables:\nUses reframe() from dplyr to summarize key statistics.\nComputes quantiles at 0%, 25%, 50%, 75%, and 100% using quantile().\n\nThese represent the minimum, first quartile (Q1), median (Q2), third quartile (Q3), and maximum values.\n\nApplies the scales::percent() function:\n\nConverts numeric quantile probabilities (0, 0.25, 0.5, etc.) into formatted percentages (0%, 25%, 50%, 75%, 100%).\n\nCreates a clean summary table:\nUses kable() to display the quantile data in a readable format.\n\nCustomizes column names: Percentile, MPG, Cylinders, and Weight.\nCenters all columns and adds a caption: “Quantiles of MTCARS”.\n\nImproves table appearance:\n\nUses kable_styling(font_size = 12) from kableExtra to make the table more visually appealing.\n\n\n\nrm(list = ls())\n\ncars &lt;- mtcars %&gt;%\n  reframe(quantile   = scales::percent(c(0, 0.25, 0.5, 0.75 ,1)),\n            mpg      = quantile(mpg, c(0, 0.25, 0.5, 0.75, 1)),\n            cyl      = quantile(cyl, c(0, 0.25, 0.5, 0.75, 1)),\n            wt       = quantile(wt, c(0, 0.25, 0.5, 0.75, 1)))\n\nkable(cars,\n      col.names = c('Percentile', \n                    'MPG',\n                    'Cyliners',\n                    'Weight'),\n      align = c('c','c','c','c'),\n      caption = 'Quantiles of MTCARS') %&gt;%\nkable_styling(font_size = 12)\n\n\nQuantiles of MTCARS\n\n\nPercentile\nMPG\nCyliners\nWeight\n\n\n\n\n0%\n10.400\n4\n1.51300\n\n\n25%\n15.425\n4\n2.58125\n\n\n50%\n19.200\n6\n3.32500\n\n\n75%\n22.800\n8\n3.61000\n\n\n100%\n33.900\n8\n5.42400",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Central Tendency</span>"
    ]
  },
  {
    "objectID": "mod-2-3-variance.html",
    "href": "mod-2-3-variance.html",
    "title": "13  Measures of Disperson",
    "section": "",
    "text": "13.1 Data Properties\nPreviously, we discussed measures of the central tendency of the data.\nWe used population data from the U.S. Census to estimate the population mean, \\(/mu\\), as well as the median.\nWe used sample data from the mtcars dataset to estimate the sample average, \\(\\bar{x}\\), as well as the sample median.\nWe also used R and RStudio to estimate the number of observations, the minimum value for a variable, and the maximum value for a variable.\nThe measures of central tendency estimate the middle of the data, however, we also noted that outliers can influence the sample average. We discussed how to trim the data to reduce the influence of outliers.\nThe measures of central tendency do not provide us information about the spread or dispersion of the data.\nAre the data “tightly clustered” around the measure of central tendency or are the data “spread out?”\nWe want to know the spread of the data relative to the center of the data.\nTo this end, we will estimate measure of the variance and standard deviation.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Measures of Disperson</span>"
    ]
  },
  {
    "objectID": "mod-2-3-variance.html#population-variance",
    "href": "mod-2-3-variance.html#population-variance",
    "title": "13  Measures of Disperson",
    "section": "13.2 Population Variance",
    "text": "13.2 Population Variance\nOne measure of the dispersion (spread) of the data is the range which is equal to the distance between the minimum and maximum observations in the data.\nWe could estimate the average distance of the observations from the mean or:\n\\[\\text{average mean deviation} = \\frac{1}{N} \\sum_{i = 1}^N (x_i - \\mu)\\]\nHowever, if sum of the mean deviations is equal to zero in the population, the average of the mean deviations will also be zero in the population.\nWe note that the sum of the squared mean deviations will not be zero.\nThe population variance, \\(\\sigma^2\\), is equal to the average of the sum of the squared mean deviations:\n\\[\\text{Population Variance} = \\sigma^2 = \\frac{1}{N} \\sum_{i = 1}^N (x_i - \\mu)^2\\]",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Measures of Disperson</span>"
    ]
  },
  {
    "objectID": "mod-2-3-variance.html#population-standard-deviation",
    "href": "mod-2-3-variance.html#population-standard-deviation",
    "title": "13  Measures of Disperson",
    "section": "13.3 Population Standard Deviation",
    "text": "13.3 Population Standard Deviation\nAs noted previously, the population variance, \\(\\sigma^2\\), is the average of the squared mean deviations:\n\\[\\sigma^2 = \\frac{1}{N} \\sum_{i = 1}^N (x_i - \\mu)^2\\]\nThe population variance, \\(\\sigma^2\\), may difficult to interpret as \\(\\sigma^2\\) is measured in the squared units of the variable of interest.\nIn other words, if we were measuring the variance of total population, the variance would be in individuals-squared units. If we were measuring the variance of income, the variance would be in income-squared units.\nThe population standard deviation, \\(\\sigma\\), is the positive square root of the population standard deviation.\n\\[\\sigma = \\sqrt{\\frac{1}{N} \\sum_{i = 1}^N (x_i - \\mu)^2}\\]The standard deviation is measured in the same units as the variable of interest.\nLastly, we note that if we have two variables \\(x\\) and \\(y\\), then \\(x\\) is less dispersed than \\(y\\) if \\(\\sigma_x &lt; \\sigma_y\\).",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Measures of Disperson</span>"
    ]
  },
  {
    "objectID": "mod-2-3-variance.html#variance-example",
    "href": "mod-2-3-variance.html#variance-example",
    "title": "13  Measures of Disperson",
    "section": "13.4 Variance Example",
    "text": "13.4 Variance Example\nIn the example below, we create a tibble of simulated population data.\nThere are 1,000,000 observations drawn from a random normal distribution with a population mean of 50.5 and a standard deviation of 5.\nIn other words, we are creating a population with a known mean and known standard deviation.\nSince the variance is the square of the standard deviation, we know the variance also.\nFor a random variable, \\(X\\) that is distributed normally with mean \\(\\mu\\) and variance \\(\\sigma^2\\), we can express this distribution of \\(X\\) as:\n\\[X \\sim N(\\mu, \\sigma^2 )\\]\nWe use the summarize function for this example.\nWe estimate the population variance manually and using the var function.\nWe then estimate the population standard deviation manually and using the sd function.\nWe do this to illustrate the manual estimates and estimates using the functions are the same.\nAn additional note that each time you run the code, a new population is generated, and the descriptive statistics may change.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Measures of Disperson</span>"
    ]
  },
  {
    "objectID": "mod-2-3-variance.html#census-example",
    "href": "mod-2-3-variance.html#census-example",
    "title": "13  Measures of Disperson",
    "section": "13.5 Census Example",
    "text": "13.5 Census Example\nIn the code chunk below, we replicate the example above but with actual data from the U.S. Census for the total population of counties and county-equivalent geographies in the United States.\nNote the difference between the mean and median population estimates. The relatively large counties influence the population mean and ‘pull’ it away from the population median.\n\nrm(list = ls())\n\nlibrary(censusapi)\nlibrary(dplyr)\nlibrary(kableExtra)\nlibrary(tidyverse)\n\ncounty_pop &lt;- getCensus(name = \"acs/acs5\",\n            vintage = 2023,\n            key     = \"9c1637a56ff93f0af6b4b1d0547ea048fe668175\",\n            vars    = c(\"NAME\",\n                        \"B01001_001E\"),\n            region  = \"county:*\") %&gt;%\nrename(pop = B01001_001E) %&gt;%\nsummarize(med_pop  = median(pop),\n          mean_pop = mean(pop),\n          var_pop  = var(pop),\n          sd_pop   = sd(pop))\n\nkable(county_pop,\n      col.names = c('Median', 'Mean',\n                    'Variance', 'Std. Dev'),\n      align     = 'c',\n      digits    = 2,\n      caption = 'Mean, Variance, and Standard Deviation, County Population') %&gt;%\nkable_styling(font_size = 12)\n\n\nMean, Variance, and Standard Deviation, County Population\n\n\nMedian\nMean\nVariance\nStd. Dev\n\n\n\n\n25967\n104172.1\n108681584571\n329668.9",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Measures of Disperson</span>"
    ]
  },
  {
    "objectID": "mod-2-3-variance.html#sample-variance",
    "href": "mod-2-3-variance.html#sample-variance",
    "title": "13  Measures of Disperson",
    "section": "13.6 Sample Variance",
    "text": "13.6 Sample Variance\nThe sample variance, \\(s^2\\), is estimated by:\n\\[s^2 = \\frac{1}{n-1} \\sum_{i = 1}^N (x_i - \\bar{x})^2\\]\nOne might ask, “why do we divide by \\(n-1\\) instead of \\(n\\)?”\nThe population mean \\(\\mu\\) is a known, definite mean. It does not require estimation.\nThe sample average, \\(\\bar{x}\\) is an estimate of the population mean \\(\\mu\\).\nIf \\(\\mu\\) is known, then we can reconstitute the data with \\(n-1\\) values.\nWith 100 observations and \\(\\mu = 50\\), then the \\(n-1\\) values can take on any value, but the n-th value is constrained so \\(\\mu = 50\\).\nThe loss of a degree of freedom requires the use \\(n-1\\) in the sample variance instead of \\(n\\).",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Measures of Disperson</span>"
    ]
  },
  {
    "objectID": "mod-2-3-variance.html#sample-standard-deviation",
    "href": "mod-2-3-variance.html#sample-standard-deviation",
    "title": "13  Measures of Disperson",
    "section": "13.7 Sample Standard Deviation",
    "text": "13.7 Sample Standard Deviation\nThe sample variance, \\(s^2\\), is estimated by:\n\\[s^2 = \\frac{1}{n-1} \\sum_{i = 1}^N (x_i - \\bar{x})^2\\]\nThe sample standard deviation, \\(s\\), is estimated by:\n\\[s = \\sqrt{\\frac{1}{n-1} \\sum_{i = 1}^N (x_i - \\bar{x})^2}\\] R (as with most programs) calculates the sample variance and sample standard deviation.\nAs \\(n\\) increases, the impact of dividing by \\(n-1\\) rather than \\(N\\) declines.\nIf you are worried about \\(n-1\\), then you are likely to have other issues (sample size) of higher concern.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Measures of Disperson</span>"
    ]
  },
  {
    "objectID": "mod-2-3-variance.html#sample-example",
    "href": "mod-2-3-variance.html#sample-example",
    "title": "13  Measures of Disperson",
    "section": "13.8 Sample Example",
    "text": "13.8 Sample Example\nWe simulate 100,000 observations from a normal distribution with \\(\\mu = 100\\) and \\(\\sigma = 8.5\\).\nWe then take a random sample of 1,000 observations from the population and estimate the variance manually and with the var function in summarize\nThe slice_sample function is used to randomly select rows from a data frame.\nThe manually calculated sample variance using \\((n-1)\\) is equal to the variance obtained from the var function in R illustrating that R generates its variance estimate using the sample variance formula.\nAs \\(\\sigma\\) is the square root of \\(\\sigma^2\\), the same discussion applies.\nIt is interesting to note that a new set of values for \\(X\\) is generated each time the code is run, changing the resulting sample descriptive statistics.\nTry changing the sample size, that is, changing from n = 1000 to n = 50, and observe what happens to the sample statistics for variance and standard deviation across several runs.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Measures of Disperson</span>"
    ]
  },
  {
    "objectID": "mod-2-3-variance.html#coefficient-of-variation",
    "href": "mod-2-3-variance.html#coefficient-of-variation",
    "title": "13  Measures of Disperson",
    "section": "13.9 Coefficient of Variation",
    "text": "13.9 Coefficient of Variation\nThe coefficient of variation is a measure of how “large” the standard deviation is relative to the mean.\nThe coefficient of variation for the population is:\n\\[\\text{coefficient of variation} = \\frac{\\sigma}{\\mu}\\] The coefficient of variation for a sample is:\n\\[\\text{coefficient of variation} = \\frac{s}{\\bar{x}}\\]\nThe higher the coefficient of variation, the greater the level of dispersion of observations around the mean.\nIn finance, the coefficient of variation estimates how much volatility, or risk, is assumed in comparison to the amount of return expected from investments.\nThe lower the coefficient of variation, the better risk-return trade-off.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Measures of Disperson</span>"
    ]
  },
  {
    "objectID": "mod-2-3-variance.html#tidyquant-example",
    "href": "mod-2-3-variance.html#tidyquant-example",
    "title": "13  Measures of Disperson",
    "section": "13.10 Tidyquant Example",
    "text": "13.10 Tidyquant Example\nWe use the tidyquant package to obtain stock price data for Apple, Ford, General Motors, Gamestop, IBM, and Netflix.\nWe then estimate the coefficient of variation for each of these corporations.\nFrom January 2020 to July 2025, IBM had the lowest coefficient of variation, that is, it was the least volatile relative to its mean.\nOver the same period, Netflix and Gamestop has the highest coefficients of variation, that is, these stocks were relatively volatile when compared to IBM or Ford.\n\nrm(list = ls())\n\nlibrary(censusapi)\nlibrary(dplyr)\nlibrary(kableExtra)\nlibrary(tidyverse)\nlibrary(tidyquant)\n\ntickers &lt;- c('AAPL', 'F',\n             'GM', 'GME',\n             'IBM', 'NFLX')\n\nprices &lt;- tq_get(tickers, \n                  from = '2010-01-01',\n                  to   = \"2025-07-31\",\n                  get  = \"stock.prices\")\n\n\ncoef_var &lt;- prices %&gt;%\n  group_by(symbol) %&gt;%\n  summarize(cv = sd(close)/mean(close)) %&gt;%\n  arrange(cv)\n\nkable(coef_var,\n      col.names = c('Company',\n                    'Coefficient of Variation'),\n      align     = c('c','c'),\n      caption   = 'Coefficient of Variation') %&gt;%\nkable_styling(font_size = 12)\n\n\nCoefficient of Variation\n\n\nCompany\nCoefficient of Variation\n\n\n\n\nIBM\n0.2096402\n\n\nF\n0.2307120\n\n\nGM\n0.2413333\n\n\nAAPL\n0.9291908\n\n\nGME\n0.9739563\n\n\nNFLX\n0.9909600",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Measures of Disperson</span>"
    ]
  },
  {
    "objectID": "mod-2-4-zscores.html",
    "href": "mod-2-4-zscores.html",
    "title": "14  Z-Scores",
    "section": "",
    "text": "14.1 Z-Scores\nFor \\(i\\) observations in a population, the population mean deviations are equal to:\n\\[d_i = x_i - \\mu\\]\nFor \\(i\\) observations in a sample, the sample mean deviations are equal to:\n\\[d_i = x_i - \\bar{x}\\] The mean deviations frame our discussion of the data in terms of the center of the data.\nWe lack information, however, on whether the mean deviation is “large” or “small” relative to the dispersion of the data.\nThe z-score or standard score is a measure of the mean deviation of an observation relative to the standard deviation of the variable.\nIn the population, the z-score for an observation is:\n\\[Z = \\frac{x_i - \\mu}{\\sigma}\\]\nIn the sample, the Z-score for an observation is:\n\\[Z = \\frac{x_i - \\bar{x}}{s}\\]\nThe Z-score can be placed on a normal distribution curve and provides a measure in standard deviation units.\nIf \\(Z_{x1} = 2\\) then the observation \\(x_1\\) is two standard deviations to the right of \\(\\mu\\).\nIf \\(Z_{x2} = -0.75\\), then the observation \\(x_2\\) is 0.75 observations to the left of \\(\\mu\\).\nZ-scores allow you to compare results to a normally distributed population. If you know, for example, that someone’s weight is 175 pounds, you might want to compare it to the average persons weight. The z-score compares the difference of the individual’s weight with the average person’s weight and adjusts it for the dispersion of the data.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Z-Scores</span>"
    ]
  },
  {
    "objectID": "mod-2-4-zscores.html#calculating-z-scores",
    "href": "mod-2-4-zscores.html#calculating-z-scores",
    "title": "14  Z-Scores",
    "section": "14.2 Calculating Z-scores",
    "text": "14.2 Calculating Z-scores\nAssume that you have a standardized test where the mean is \\(\\mu = 150\\) and the standard deviation is \\(\\sigma = 25\\).\nIf we assume a normal distribution and an individual scores 190.\n\\[Z_{190} = \\frac{x_i - \\mu}{\\sigma} = \\frac{190 - 150}{25} = 1.6\\] A Z-score of 1.6 means that the individual’s score of 190 is 1.6 standard deviations from the population mean. Given the value of the Z-score is positive, this means the score of 190 lies 1.6 standard deviations to the right of the population mean.\nWhat is an individual scored 100?\n\\[Z_{100} = \\frac{x_i - \\mu}{\\sigma} = \\frac{100 - 150}{25} = -2\\] A Z-score of -2 means that the individual’s score is 2 standard deviations to the left of the population mean. The negative value of the Z-score means that the individual scored less than the population mean.\nLater in the class we will use a Z-table and then R to determine the probabilities associated with Z-scores.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Z-Scores</span>"
    ]
  },
  {
    "objectID": "mod-2-4-zscores.html#z-scores-in-r",
    "href": "mod-2-4-zscores.html#z-scores-in-r",
    "title": "14  Z-Scores",
    "section": "14.3 Z-Scores in R",
    "text": "14.3 Z-Scores in R\nIn the following example, we generate a simulated population of 10,000 observations with \\(\\mu = -25\\) and \\(\\sigma = 2.9\\).\nWe then generate the population mean and population standard deviation for the simulated population.\nThe next step is estimating the z-score of each observation.\nWe then output the first five observations to the table. Again, you may find it useful to note how the data in the table changes each time your run the code.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Z-Scores</span>"
    ]
  },
  {
    "objectID": "mod-2-4-zscores.html#module-summary",
    "href": "mod-2-4-zscores.html#module-summary",
    "title": "14  Z-Scores",
    "section": "14.4 Module Summary",
    "text": "14.4 Module Summary\nWe use descriptive statistics to develop an understanding of the properties of the data.\nWe have discussed two broad properties of the data:\n\nThe center of the data\nThe spread of the data\n\nWe will work on the shape of the data in coming modules.\nNow, having worked with measures of the center and spread, we can turn our attention to the question of co-movement.\nDo two variables “move” together in some systematic fashion?\nWhat measures might suggest a potential relationship between two variables of interest?\nIn our next module, we will focus on covariance and correlation.",
    "crumbs": [
      "Descriptive Statistics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Z-Scores</span>"
    ]
  },
  {
    "objectID": "mod-3-0-overview.html",
    "href": "mod-3-0-overview.html",
    "title": "15  Module 3 Overview",
    "section": "",
    "text": "15.1 Introduction\nWelcome to Module 3 of ECON 700.\nThis module introduces students to bivariate data analysis through the concepts of covariance and correlation. Building on prior discussions of univariate statistics, it explores how two variables move together and the extent to which their relationship can be quantified. Covariance is presented as a measure of joint variability that indicates whether two variables tend to increase or decrease together. Students learn that while the sign of covariance conveys direction (positive or negative association), its magnitude is difficult to interpret due to dependence on the units of measurement.\nTo overcome this limitation, the module introduces the Pearson correlation coefficient—a standardized, unitless measure that captures the strength and direction of linear relationships between two variables. Through practical examples using R and real-world data such as mtcars and World Bank indicators, students compute, interpret, and compare covariance and correlation values. The module concludes by emphasizing that correlation measures association, not causation, and that careful interpretation is required when evaluating statistical relationships.",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Module 3 Overview</span>"
    ]
  },
  {
    "objectID": "mod-3-0-overview.html#learning-objectives",
    "href": "mod-3-0-overview.html#learning-objectives",
    "title": "15  Module 3 Overview",
    "section": "15.2 Learning Objectives",
    "text": "15.2 Learning Objectives\nBy the end of this module, you should be able to:\n\nDefine covariance and correlation as measures of association between two quantitative variables.\nCompute sample and population covariance and correlation using R.\nInterpret the sign and magnitude of covariance and correlation coefficients in applied examples.\nExplain how changes in units of measurement affect covariance but not correlation.\nDistinguish between statistical association and causal relationships in bivariate data.\nApply covariance and correlation measures to real-world datasets to evaluate linear relationships.",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Module 3 Overview</span>"
    ]
  },
  {
    "objectID": "mod-3-0-overview.html#readings-resources",
    "href": "mod-3-0-overview.html#readings-resources",
    "title": "15  Module 3 Overview",
    "section": "15.3 Readings & Resources",
    "text": "15.3 Readings & Resources\n\nBarbara Illowsky and Susan Dean. Introductory Statistics 2e. OpenStax. (Chapter 2). Available for free online at https://openstax.org/books/introductory-statistics-2e/pages/2-introduction\nIrizarry, R. (2025). Introduction to Data Science: Data Wrangling and Visualization with R. (Chapters 1-2). Available for free at: https://rafalab.dfci.harvard.edu/dsbook-part-1/\nWickham, H., & Grolemund, G. (2017). R for Data Science. (Chapters 1–3).\n\nOnline R documentation: https://cran.r-project.org/manuals.html\n\nRStudio Cheat Sheets",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Module 3 Overview</span>"
    ]
  },
  {
    "objectID": "mod-3-0-overview.html#activities",
    "href": "mod-3-0-overview.html#activities",
    "title": "15  Module 3 Overview",
    "section": "15.4 Activities",
    "text": "15.4 Activities\n\nComplete the hands-on coding exercises embedded in each lesson.\n\nComplete the weekly class assignment.\n\nParticipate in the discussion form.\n\nTake the weekly knowledge quiz.",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Module 3 Overview</span>"
    ]
  },
  {
    "objectID": "mod-3-0-overview.html#lessons-in-this-module",
    "href": "mod-3-0-overview.html#lessons-in-this-module",
    "title": "15  Module 3 Overview",
    "section": "15.5 Lessons in this Module",
    "text": "15.5 Lessons in this Module\n\n3.1 – Skewness\n3.2 – Chebyshev’s Theorem\n3.3 - Covariance and Correlation\n\n\nNext: Start with Skewness.",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Module 3 Overview</span>"
    ]
  },
  {
    "objectID": "mod-3-1-skewness.html",
    "href": "mod-3-1-skewness.html",
    "title": "16  Skewness",
    "section": "",
    "text": "16.1 Defining Skewness\nIn addition to measures of central tendency (population mean and sample average) and measures of dispersion (variance and standard deviation), we can investigate the skew of data.\nAre the data “shifted” to the left or right of the center? Are the data “clustered” around the measure of central tendency?\nSkewness measures the asymmetry of a probability distribution of a real-valued random variable around its mean. Skewness can be positive, negative, or undefined.\nFor a distribution with a single peak, a negative skew implies that the tail is on the left side of the distribution. A positive skew implies that the tail is on the right side of the distribution. A zero skew implies that the tails ‘balance’ which may mean the distribution is symmetric.\nThe Fisher-Pearson standardized moment coefficient is used by R and other major statistical software packages to measure skewness in a univariate sample. The sample skewness measure is equal to:\n\\[G_1 = \\frac{n}{(n-1)(n-2)}\\sum_{i=1}^{n} \\Big( \\frac{x_i - \\bar{x}}{s} \\Big)^3\\]",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Skewness</span>"
    ]
  },
  {
    "objectID": "mod-3-1-skewness.html#skewness-example",
    "href": "mod-3-1-skewness.html#skewness-example",
    "title": "16  Skewness",
    "section": "16.2 Skewness Example",
    "text": "16.2 Skewness Example\nIn the following example, we construct a vector of observations for the variables x, y, and z.\nWe install and use the moments package to estimate skewness.\nThe first vector, x, has a mean of 7 and a median of 7. The observations are symmetrically distributed around 7, that is, the mirror are ‘reflected’ around the mean.\nIn a perfectly symmetrical distribution, the mean and median are the same. Note also that the estimate of skewness is equal to zero, that is, the tails of the distribution are symmetrical.\nThe second vector, y, has a mean of 6.3 and a median of 6.5. The estimate of skewness is -0.613. The negative skew means that the tail of the left side of the distribution is longer than the tail on the right side of the distribution.\nIn other words, if skewness is negative, the mass of the distribution is concentrated to the right, that is, the left tail is longer.\nThe third vector, z has a mean of 7.214 and a median of 7.0. The estimate of skewness of is 0.442. The positive skew means that the right tail of the distribution longer.\nIn other words, if skewness is positive, the mass of the distribution is concentrated to the left, that is, the right tail is longer.\n\nrm(list = ls())\n\n#Use moments package for skewness\n\nlibrary(dplyr)\nlibrary(kableExtra)\nlibrary(moments)\n\n# Define data vectors\n\nx &lt;- c(4, 5, 6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 9, 10)\n\ny &lt;- c(4, 5, 6, 6, 6, 7, 7, 7, 7, 8)\n\nz &lt;- c(5, 6, 6, 6, 7, 7, 7, 7, 7, 8, 8, 8, 9, 10)\n\nx_stats &lt;- tibble(name = 'X-Stats',\n                  mean   = mean(x),\n                  median = median(x),\n                  skew   = skewness(x))\n\ny_stats &lt;- tibble(name = 'Y-Stats',\n                  mean   = mean(y),\n                  median = median(y),\n                  skew   = skewness(y))\n\nz_stats &lt;- tibble(name = 'Z-Stats',\n                  mean   = mean(z),\n                  median = median(z),\n                  skew   = skewness(z))\n\nstats &lt;- rbind(x_stats, y_stats, z_stats)\n\nkable(stats,\n      align     = 'c',\n      digits    = 3,\n      col.names = c('Source','Mean','Median','Skew')) %&gt;%\nkable_classic()\n\n\n\n\nSource\nMean\nMedian\nSkew\n\n\n\n\nX-Stats\n7.000\n7.0\n0.000\n\n\nY-Stats\n6.300\n6.5\n-0.613\n\n\nZ-Stats\n7.214\n7.0\n0.442",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Skewness</span>"
    ]
  },
  {
    "objectID": "mod-3-1-skewness.html#interpreting-skewness",
    "href": "mod-3-1-skewness.html#interpreting-skewness",
    "title": "16  Skewness",
    "section": "16.3 Interpreting Skewness",
    "text": "16.3 Interpreting Skewness\nSkewness is a measure of the symmetry of the data. Negative skewness generally implies that the mean is less than the median. Negative skewness means that the left tail of the data is longer than the right tail of the data. Positive skewness implies that the mean is greater than the median and implies that the right tail of the data are longer than the left tail of the data.\nIf skewness is negative, the data are left-skewed.\nIf skewness is positive, the data are right-skewed.1\nFollowing Bulmer (1979), the following rules of thumb are useful in interpreting skewness.\n\nIf skewness is less than -1 or greater than 1, the data are highly skewed.\nIf skewness is between -1 and -1/2 or between 1/2 and 1, the data are moderately skewed.\nIf skewness is between -1/2 and 1/2, the data are approximately symmetric.\nIf skewness is 0, the data are perfectly symmetric.\n\nAt a minimum, the following points regarding the skewness measure can be made:\n\nThe sign represents the direction of skewness.\nThe measure compares to a symmetric distribution (i.e. the normal distribution).\nValues that are far from zero imply a non-normal or skewed population.\nThe measure has an adjustment for sample size.\nIn large samples, the adjustment is of little consequence.",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Skewness</span>"
    ]
  },
  {
    "objectID": "mod-3-1-skewness.html#skewness-illustration",
    "href": "mod-3-1-skewness.html#skewness-illustration",
    "title": "16  Skewness",
    "section": "16.4 Skewness Illustration",
    "text": "16.4 Skewness Illustration\n\n\n\nRelationship Between Mean, Median, and Mode\n\n\nBy Diva Jain - https://codeburst.io/2-important-statistics-terms-you-need-to-know-in-data-science-skewness-and-kurtosis-388fef94eeaa, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=84219892",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Skewness</span>"
    ]
  },
  {
    "objectID": "mod-3-1-skewness.html#footnotes",
    "href": "mod-3-1-skewness.html#footnotes",
    "title": "16  Skewness",
    "section": "",
    "text": "For an extended discussion, see Doane and Seward (2011), “Measuring Skewness: A Forgotten Statistic?” Available at: http://jse.amstat.org/v19n2/doane.pdf↩︎",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Skewness</span>"
    ]
  },
  {
    "objectID": "mod-3-2-normal.html",
    "href": "mod-3-2-normal.html",
    "title": "17  Chebyshev’s Theorem",
    "section": "",
    "text": "17.1 Z-Scores\nRecall that we previously defined a Z-score as a measure of the number of standardized deviations an observation is from the mean.\nGiven population data distributed with mean, \\(\\mu\\), and standard deviation, \\(\\sigma\\), the Z-score for an observation, \\(x\\), is denoted as:\n\\[\nZ_x = \\frac{x - \\mu}{\\sigma}\n\\]\nIf the Z-score of an observation was -2.5, then we would state that the observation lies 2.5 standard deviations to the left of the mean. If the Z-score is equal to 1.75, then we would state that the observation lies 1.75 standard deviations to the right of the population mean.\nLet \\(x_1 = 50\\), \\(\\mu_{x_1} = 20\\), and \\(\\sigma_{x_1}=5\\), then the \\(z_{x_1}\\) is equal to\n\\[\nz_{x_1} = \\frac{x_1 - \\mu}{\\sigma} = \\frac{50-20}{5} = 6\n\\]\nThe observation \\(x_1\\) is 6 standard deviations from the mean of 20. Given that \\(z_{x_1}\\) is positive, we know that the observation \\(x_1\\) is 6 standard deviations to the right of \\(\\mu_{x_1}\\).",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Chebyshev's Theorem</span>"
    ]
  },
  {
    "objectID": "mod-3-2-normal.html#chebyshevs-theorem",
    "href": "mod-3-2-normal.html#chebyshevs-theorem",
    "title": "17  Chebyshev’s Theorem",
    "section": "17.2 Chebyshev’s Theorem",
    "text": "17.2 Chebyshev’s Theorem\nChebyshev’s Theorem states at least \\((1 - 1 / z^2)\\) of the data values must be within \\(z\\) standard deviations of the mean where \\(z\\) is any value greater than 1.\nSince the theorem is independent of the underlying distribution, we can apply Chebyshev’s theorem to a data set without worrying about how the data are distributed.\nWith this in mind, let \\(z = 2\\), \\(z = 3\\), and \\(z=6\\), then\n\\[z = 2 \\rightarrow (1 - \\frac{1}{2^2}) = 1 - 1/4 = 0.750 \\]\n\\[z = 3 \\rightarrow (1 - \\frac{1}{3^2}) = 1 - 1/9 = 0.889\\] \\[z = 4 \\rightarrow (1 - \\frac{1}{4^2}) = 1 - 1/16 = 0.972\\]\nChebyshev’s theorem implies that at least 75% of observations will lie within 2 standard deviations of the mean and at least 88.9% of observations with lie within 3 standard deviations of the mean.\nThis is quite useful when you do not know the underlying distribution of the data. The theorem provides a conservative estimate relative to the Empirical Rule which applies only to normal distributions and that we will explore later.",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Chebyshev's Theorem</span>"
    ]
  },
  {
    "objectID": "mod-3-2-normal.html#chebyshevs-examples",
    "href": "mod-3-2-normal.html#chebyshevs-examples",
    "title": "17  Chebyshev’s Theorem",
    "section": "17.3 Chebyshev’s Examples",
    "text": "17.3 Chebyshev’s Examples\n\n17.3.1 Example 1\nAssume that you have a dataset with a mean of 100 and a standard deviation of 10.\n\\[\n\\mu = 100 \\\\\n\\sigma = 10\n\\]\nYou are interested in a range of 3 standard deviations.\n\\[\n\\mu - 2\\sigma = 100 - 3 \\times 10 = 70 \\\\\n\\mu + 2\\sigma = 100 + 3 \\times 10 = 130\n\\]\nChebyshev’s Theorem tells you at least 89% of observations fall between 70 and 130. This implies that no more than 11% of observations fall outside this range.\n\n\n17.3.2 Example 2\nAssume that a class takes a test. The mean score on the test is 75 and the standard deviation is 5. What proportion of scores fall between 65 and 85?\nGiven the mean is 75, you should note that 65 is 2 standard deviations less than the mean and 85 is 2 standard deviations greater than the mean.\nBy Chebyshev’s Theorem, this means that at least 75% of observations fall between 65 and 85. This implies that no more than 25% of observations fall outside this range.\n\n\n17.3.3 Example 3\nLet \\(\\mu = 80\\) and \\(\\sigma = 4\\).\n\\[ \\mu - 2\\sigma = 80 - (2 \\times 4) = 72 \\\\ \\mu + 2\\sigma = 80 + (2 \\times 4) = 88\\]\nAt least 75% of observations for a distribution with \\(\\mu = 80\\) and \\(\\sigma = 4\\) lie in the (72,88) range.\n\\[ \\mu - 3\\sigma = 80 - (3 \\times 4) = 68 \\\\ \\mu + 3\\sigma = 80 + (3 \\times 4) = 92 \\]\nAt least 75% of observations lie in the (68,92) range.",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Chebyshev's Theorem</span>"
    ]
  },
  {
    "objectID": "mod-3-2-normal.html#the-normal-distribution",
    "href": "mod-3-2-normal.html#the-normal-distribution",
    "title": "17  Chebyshev’s Theorem",
    "section": "17.4 The Normal Distribution",
    "text": "17.4 The Normal Distribution\nThe normal distribution is undoubtedly one of the most important, if not the most important, distribution in statistics. While there are technically an infinite number of normal distributions, we often refer to “the normal distribution” to discuss the properties of the distribution. Unlike the previous examples which have been collections of discrete observations, the normal distribution is continuous.\nA normal distribution in \\(X\\) with mean \\(\\mu\\) and variance \\(\\sigma^2\\) is a distribution resulting from the probability distribution function that is defined on the \\(x \\in (-\\infty, \\infty)\\) interval and is equal to:\n\\[\nP(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-(x - \\mu) / (2 \\sigma^2)}\n\\]\nWe will discuss the properties of the normal and other distributions at greater length in coming modules.\nFor now, we will focus on the general properties that help us think about measures of central tendency, variability, and the shape of the data.\nThe normal distribution has the following properties.\n\nThe mean, mode, and median are all equal.\nThe normal distribution is symmetric around \\(\\mu\\)\nExactly 50% of the values lie to the left of \\(\\mu\\)\nExactly 50% of the values lie to the right of \\(\\mu\\)\nThe total area under the curve is equal to 1",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Chebyshev's Theorem</span>"
    ]
  },
  {
    "objectID": "mod-3-2-normal.html#the-empirical-rule",
    "href": "mod-3-2-normal.html#the-empirical-rule",
    "title": "17  Chebyshev’s Theorem",
    "section": "17.5 The Empirical Rule",
    "text": "17.5 The Empirical Rule\nThe Empirical rule is based on Chebyshev’s theorem and, given a normal distribution, states that:\n\nApproximately 68% of observations lie within one standard deviation of \\(\\mu\\).\nApproximately 95% of observations lie within two standard deviations of \\(\\mu\\).\nApproximately 99% of observations lie within three standard deviations of \\(\\mu\\).\n\n\n\n\nThe Normal Distribution\n\n\n\n17.5.1 Example 1\nLet \\(\\mu = 25\\) and \\(\\sigma = 5\\) then, by the empirical rule for a normal distribution, we know:\n\nApproximately 68% of observations lie between 20 and 30 or \\(\\mu \\pm \\sigma\\).\nApproximately 95% of observations lie between 15 and 35 or \\(\\mu \\pm 2\\sigma\\).\nApproximately 99% of observations lie between 10 and 40 or \\(\\mu \\pm 3\\sigma\\).\n\nWe can confirm this by estimating the Z-Score for 10, 15, 20, 30, 35, and 40.\n\\[\nZ(10) = \\frac{10 - 25}{5} = -3\n\\]\n\\[\nZ(15) = \\frac{15 - 25}{5} = -2\n\\]\n\\[\nZ(20) = \\frac{20 - 25}{5} = -1\n\\]\n\\[\nZ(30) = \\frac{30 - 25}{5} = 1\n\\]\n\\[\nZ(35) = \\frac{35 - 35}{5} = 2\n\\]\n\\[\nZ(40) = \\frac{40 - 25}{5} = 3\n\\]\n\n\n17.5.2 Example 2\nAssume that a pizza delivery restaurant has a mean delivery time of 32 minutes with a standard deviation of 4 minutes. Assume that delivery times are normally distributed.\nWhat is the range of times in which 68%, 95%, and 95% of deliveries occur?\nAccording to the Empirical Rule,\n\\[\n\\text{68\\%} \\rightarrow  \\mu \\pm \\sigma = 32 \\pm 4 = (28,36)\n\\]\n\\[\n\\text{95\\%} \\rightarrow \\mu \\pm 2\\sigma = 32 \\pm 8 = (24,40)\n\\]\n\\[\n\\text{99\\%} \\rightarrow \\mu \\pm 3\\sigma = 32 \\pm 12 = (20,44)\n\\]",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Chebyshev's Theorem</span>"
    ]
  },
  {
    "objectID": "mod-3-3-correlation.html",
    "href": "mod-3-3-correlation.html",
    "title": "18  Correlation",
    "section": "",
    "text": "18.1 Introduction\nTo this point, we have mostly examined methods of describing one variable, that is, univariate analysis.\nHowever, we may wish to do more than describe the properties of one variable.\nWe may want to explore a potential relationship (or absence of one) between two variables. Moving from univariate to bivariate analysis starts with a discussion of measures of association between two variables.\nTo start our discussion, we need to understand the expectations operator.",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "mod-3-3-correlation.html#the-expectations-operator",
    "href": "mod-3-3-correlation.html#the-expectations-operator",
    "title": "18  Correlation",
    "section": "18.2 The Expectations Operator",
    "text": "18.2 The Expectations Operator\nGiven a function \\(f(x)\\) in the variable \\(x\\), the expectation value is denoted as \\(E[X]\\).\nFor a single, discrete variable \\(X\\) with probability density function \\(P(X)\\), the expectation of \\(X\\) is defined as:\n\\[\nE[X] = \\sum_{X} f(x) P(x)\n\\]\nIf \\(X\\) is a continuous variable, then \\(E[X]\\) is defined as:\n\\[\nE[X] = \\int f(x) P(X) dx\n\\]\nThe expected value of a random variable is the arithmetic mean of that variable. This term has been retained in mathematical statistics to mean the long-run average for any random variable over an indefinite number of trials or samples. In other words,\n\\[\nE[X] = \\mu_x\n\\]\nThe variance of a random variable \\(X\\) is defined as the expected (average) squared deviation of the values of this random variable about their mean. That is,\n\\[var(x) = E[(X - \\mu)^2] = E[X^2] - \\mu^2 = \\sigma_X^2\\]\nThe expectations operator adheres to the following rules.\nLet \\(X\\) and \\(Y\\) be random variables and let \\(k\\) and \\(j\\) be constants.\nThe first rule is that the expectation of a constant is a constant.\nIn other words, if \\(k=4\\), then every observation of \\(k\\) is 4 and the mean of \\(k\\) is \\(E[k] = \\mu_k = 4\\).\n\\[\nE[k] = k\n\\]\nThe second rule is that the expectation of the product of a constant and a random variable is equal to the product of a constant and the expectation of a random variable. In other words, assume that we multiply every observation of a random variable by 3 and then find the long-run mean of the random variable. This is the same as finding the long-run mean and multiplying the mean by 3.\n\\[\nE[kX] = kE[X] = k \\mu_x\n\\]\nThe third rule is that the expectation of the sum of two random variables is equal to the addition of the expectiations of the two random variables. In other words, if we add two random variables, one with the mean of 5 and the other with the mean of 10, this is the same as adding the two means together.\n\\[\nE[X+Y] = E[X] + E[Y]\n\\]\nThe fourth rule combines the second and third rules in that if you have the sum of the two random variables where each random variable is multiplied by a constant, then you can restate this as the product of the constant and the expectation of the first random variable plus the product of the constant and the expectation of the second random variable.\n\\[\nE[kX + jY] = kE[X] + jE[Y]\n\\]\nThere are a number of other expectation rules which we will cover later on in the course.",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "mod-3-3-correlation.html#covariance",
    "href": "mod-3-3-correlation.html#covariance",
    "title": "18  Correlation",
    "section": "18.3 Covariance",
    "text": "18.3 Covariance\nGiven two random variables, \\(X\\) and \\(Y\\), the covariance between these two variables can be defined as:\n\\[\ncov(X,Y) = E[(X - E[X])(Y - E[Y])]\n\\]\n\\[\ncov(X,Y) = E[(X - \\mu_x)(Y - \\mu_Y)] = E[XY] - E[X]E[Y]\n\\] The population covariance \\(\\sigma_{xy}\\) between two random variables is defined as:\n\\[\ncov(X,Y) = \\sigma_{XY} = \\sum_{i=1}^{N} \\frac{(x_i - \\mu_x)(y_i - \\mu_y)}{N}\n\\]\nThe sample covariance \\(s_{xy}\\) between two random variables is defined as:\n\\[\ncov(X,Y) = s_{XY} = \\sum_{i=1}^{n-1} \\frac{(x_i - \\bar{x})(y_i - \\bar{y})}{n-1}\n\\]\nOne point to note is that the covariance between a variable and itself is the variance of the variable.\nWe can easily see this for the population covariance by substituting \\(X\\) for \\(Y\\) or\n\\[\ncov(X,X) = \\sigma_{XX} = \\sigma_X^2 = \\sum_{i=1}^{N} \\frac{(x_i - \\mu_x)(x_i - \\mu_x)}{N} = \\sum_{i=1}^{N} \\frac{(x_i - \\mu_x)^2}{N}\n\\]",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "mod-3-3-correlation.html#scatterplots",
    "href": "mod-3-3-correlation.html#scatterplots",
    "title": "18  Correlation",
    "section": "18.4 Scatterplots",
    "text": "18.4 Scatterplots\nIn the following code chunks, we create scatterplots of car weight and miles per gallon from the mtcars data set.\nThe scatterplot of the two variables suggests that as car weight increases, miles per gallon declines.\nIn the first scatterplot, we have weight on the x-axis and miles per gallon on the y-axis.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWhat happens if we have miles per gallon on the x-axis and weight on the y-axis?\nThe same negative association appears to be present between the two variables, however, the important point is that that association is not causation, that is, we do not know if variation in one variable causes variation in another variable.\nAnother way to think about this is that we are investigating whether variables ‘move’ together in a systematic fashion.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "mod-3-3-correlation.html#covariance-example",
    "href": "mod-3-3-correlation.html#covariance-example",
    "title": "18  Correlation",
    "section": "18.5 Covariance Example",
    "text": "18.5 Covariance Example\nLet’s explore the covariance between two variables, \\(X\\), and \\(Y\\) in the following code.\nWe first create a tibble with \\(X\\) and \\(Y\\).\nWe then estimate the covariance between \\(X\\) and \\(Y\\) manually:\n\nWe estimate the mean deviations of \\(X\\)\nWe estimate the mean deviations of \\(Y\\)\nWe estimate the product of the mean deviations of \\(X\\) and \\(Y\\)\nWe estimate the product of \\(1/(n-1)\\) and the product of the mean deviations of \\(X\\) and \\(Y\\)\n\nThe result is an estimate of the sample covariance between \\(X\\) and \\(Y\\).\nWe then use the cov function to estimate the sample covariance between \\(X\\) and \\(Y\\).\nThis also illustrate that R uses the sample covariance function to estimate the covariance between two variables.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "mod-3-3-correlation.html#fred-covariance",
    "href": "mod-3-3-correlation.html#fred-covariance",
    "title": "18  Correlation",
    "section": "18.6 FRED Covariance",
    "text": "18.6 FRED Covariance\nIn the following code chunk, we want to estimate the covariance between the headline unemployment rate and the headline inflation rate.\nUsing the tidyquant package, we obtain the data from FRED.\nHowever, the data from FRED are in ‘long’ format, that is, one column contains symbols that identify the series and another column contains the values. We want to translate the data into ‘wide’ format, where each row (date) contains several columns of data.\nWe use the pivot_wider command to translate the data from long to wide format and then estimate the monthly inflation rate as the year-over-year change in the Consumer Price Index. Since the unemployment rate is not in decimal form, we divide the unemployment series by 100.\nWe then create a scatterplot before estimating the mean of each series and the covariance between the two series.\n\nrm(list = ls())\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(tidyquant)\nlibrary(scales)\n\ndf_3 &lt;- tq_get(c('UNRATE', 'CPIAUCSL'),\n               get  = 'economic.data',\n               from = '1969-01-01') %&gt;%\n  pivot_wider(names_from = symbol, values_from = price) %&gt;%\n  mutate(inflation = (CPIAUCSL - lag(CPIAUCSL, 12)) / lag(CPIAUCSL, 12),\n         UNRATE    = UNRATE/100) %&gt;%\n  filter(!is.na(inflation))\n\nggplot(data = df_3, \n       aes(x = inflation, \n           y = UNRATE)) +\ngeom_point() +\nscale_x_continuous(labels = scales::percent) +\nscale_y_continuous(labels = scales::percent) +\ntheme_classic() +\nlabs(x = \"Inflation (YoY %)\",\n     y = \"Unemployment Rate (%)\",\n     title = \"Scatterplot of Inflation and Unemployment\")\n\n\n\n\n\n\n\ndf_4 &lt;- df_3 %&gt;%\n        summarize(mean_inf = mean(inflation),\n                  mean_unr = mean(UNRATE),\n                  cov_i_u  = cov(inflation, UNRATE))\n\nkable(df_4,\n      col.names = c('Mean Inflation',\n                    'Mean Unemploymnet',\n                    'Covariance Inflation and Unemployment'),\n      align     = 'c') %&gt;%\nkable_classic()\n\n\n\n\nMean Inflation\nMean Unemploymnet\nCovariance Inflation and Unemployment\n\n\n\n\n0.0400282\n0.0606632\n2.76e-05",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "mod-3-3-correlation.html#mtcars-covariance",
    "href": "mod-3-3-correlation.html#mtcars-covariance",
    "title": "18  Correlation",
    "section": "18.7 MTCARS Covariance",
    "text": "18.7 MTCARS Covariance\nIn our last example of covariance, we return to the mtcars dataset and the variables for the weight of each car (in thousands of pounds) and the miles per gallon of each car.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "mod-3-3-correlation.html#interpreting-the-covariance",
    "href": "mod-3-3-correlation.html#interpreting-the-covariance",
    "title": "18  Correlation",
    "section": "18.8 Interpreting the Covariance",
    "text": "18.8 Interpreting the Covariance\nGiven that the sample covariance in the previous example is equal to approximately -5.12, what does this mean about the potential relationship between the two variables?\nIf \\(\\sigma_{XY} &gt; 0\\) or \\(s_{XY} &gt; 0\\), this implies that \\(X\\) and \\(Y\\) are positively linearly related, that is, as \\(X\\) increases, \\(Y\\) increases in a linear fashion.\nLikewise, If \\(\\sigma_{XY} &lt; 0\\) or \\(s_{XY} &lt; 0\\), this implies that \\(X\\) and \\(Y\\) are negatively linearly related, that is, as \\(X\\) increases, \\(Y\\) declines in a linear fashion.\nIf \\(\\sigma_{XY} \\approx 0\\) or \\(s_{XY} \\approx 0\\), this implies that \\(X\\) and \\(Y\\) are not linearly related, that is, an increase in \\(X\\) does not appear to influence \\(Y\\).\nIf \\(X\\) and \\(Y\\) are independent, then \\(\\sigma_{XY} = 0\\) and \\(s_{XY} = 0\\).\nHowever, we typically do not rely on covariance to measure the association between two variables.",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "mod-3-3-correlation.html#scaling-and-covariance",
    "href": "mod-3-3-correlation.html#scaling-and-covariance",
    "title": "18  Correlation",
    "section": "18.9 Scaling and Covariance",
    "text": "18.9 Scaling and Covariance\nThe choice of units can alter the covariance measure. In other words, you can increase or decrease covariance between two variables by changing the units of measures of one or both variables.\nWe can easily see this in the following example. We add two new variables, one that converts miles per gallon into feet per gallon mpg_ft and one that converts weight in pounds into weight in ounces wt_oz.\nThe covariance is dependent upon how each variable is measured.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "mod-3-3-correlation.html#correlation-coefficient",
    "href": "mod-3-3-correlation.html#correlation-coefficient",
    "title": "18  Correlation",
    "section": "18.10 Correlation Coefficient",
    "text": "18.10 Correlation Coefficient\nGiven that the covariance measure is affected by the choice of units of measurement, we can use the correlation coefficient to examine the relationship between two random variables.\nThe Pearson correlation coefficient is defined as the ratio of the covariance between \\(X\\) and \\(Y\\) to the product of the standard deviations of \\(X\\) and \\(Y\\) and is denoted as \\(\\rho_{XY}\\) in the population and \\(r_{XY}\\) in the sample.\nIn expectations, the Pearson correlation coefficient is equal to:\n\\[\\begin{equation}\n\\rho_{XY} = \\frac{E[(X - \\mu_x)(Y - \\mu_Y)]}{\\sigma_X \\sigma_Y}\n\\end{equation}\\]\nIn the population, the Pearson correlation coefficient, \\(\\rho_{XY}\\), is equal to:\n\\[\\begin{equation}\n\\rho_{XY} = \\frac{\\sigma_{XY}}{\\sigma_X \\sigma_Y}\n\\end{equation}\\]\nIn the sample, the Pearson correlation coefficient, \\(r_{XY}\\), is equal to:\n\\[\\begin{equation}\nr_{XY} = \\frac{s_{XY}}{s_X s_Y}\n\\end{equation}\\]\nThe Pearson correlation coefficient is bounded between -1 and 1.\nA negative sign implies a negative association between the two variables of interest, while a positive sign implies a positive association. The closer the correlation coefficient is to -1 or 1, the stronger the association between the two variables. If the correlation coefficient is equal to -1 or 1, the two variables are perfectly correlated. If the correlation coefficient is equal to 0, the two variables are uncorrelated.\nReturning to the previous example, we first manually calculate the sample covariance between car weight and miles per gallon and the sample standard deviations for these variables. We then calculate the sample correlation coefficient manually and compare it the results of the correlation function.",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "mod-3-3-correlation.html#correlation-example",
    "href": "mod-3-3-correlation.html#correlation-example",
    "title": "18  Correlation",
    "section": "18.11 Correlation Example",
    "text": "18.11 Correlation Example\nLet’s explore the correlation between two variables, \\(X\\), and \\(Y\\) in the following code.\nWe return first to our previous example.\n\nWe estimate the standard deviations of \\(X\\) and \\(Y\\)\nWe estimate the covariance between \\(X\\) and \\(Y\\)\nWe manually estimate the correlation by dividing the covariance by the product of the standard deviations.\nWe use the cor function to estimate the correlation between the two variables\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "mod-3-3-correlation.html#fred-correlation",
    "href": "mod-3-3-correlation.html#fred-correlation",
    "title": "18  Correlation",
    "section": "18.12 FRED Correlation",
    "text": "18.12 FRED Correlation\nIn the code chunk below, we again retrieve the headline unemployment rate and headline inflation series from FRED.\nThis time, however, we create two new variables.\n\nInflation_2 is equal to the inflation series times 1000\nUnemployment_2 is equal to the unemployment series time 100\n\nWe then estimate the covariance between\n\nInflation and unemployment\nInflation_2 and unemployment\nInflation and unemployment_2\n\nThe results demonstrate that the covariance measure is dependent on the scale or units of measurement and that we can inflate (or deflate) the covariance measure by scaling one or both variables.\nWe then estimate four correlation coefficients:\n\nInflation and unemployment\nInflation_2 and unemployment\nInflation and unemployment_2\nInflation_2 and unemployment_2\n\nThe correlation coefficients are equal to each other. In other words, the correlation coefficient is invariant to the scale of the variables.\n\nrm(list = ls())\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(tidyquant)\nlibrary(scales)\n\ndf_5 &lt;- tq_get(c('UNRATE', 'CPIAUCSL'),\n               get  = 'economic.data',\n               from = '1969-01-01') %&gt;%\n  pivot_wider(names_from = symbol, values_from = price) %&gt;%\n  mutate(inflation = (CPIAUCSL - lag(CPIAUCSL, 12)) / lag(CPIAUCSL, 12),\n         unrate    = UNRATE/100) %&gt;%\n  filter(!is.na(inflation)) %&gt;%\n  mutate(unrate_2 = unrate *100,\n         inflation_2 = inflation * 1000) %&gt;%\n  summarize(cov_i_u     = cov(inflation, unrate),\n            cov_i2_u    = cov(inflation_2, unrate),\n            cov_i_u2    = cov(inflation, unrate_2),\n            cor_i_u     = cor(inflation, unrate),\n            cor_i2_u    = cor(inflation_2, unrate),\n            cor_i_u2    = cor(inflation, unrate_2),\n            cor_i2_u2   = cor(inflation_2, unrate_2))\n\nkable(df_5,\n      align = 'c',\n      digits = 3,\n      col.names = c('COV(Inf, Unemp)', 'COV(Inf2, Unemp)',\n                    'COV(Inf, Unemp2)', 'COR(Inf,Unemp)',\n                    'COR(Inf2, Unemp)', 'COR(Inf, Unemp2)',\n                    'COR(Inf2, Unemp2)'))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCOV(Inf, Unemp)\nCOV(Inf2, Unemp)\nCOV(Inf, Unemp2)\nCOR(Inf,Unemp)\nCOR(Inf2, Unemp)\nCOR(Inf, Unemp2)\nCOR(Inf2, Unemp2)\n\n\n\n\n0\n0.028\n0.003\n0.056\n0.056\n0.056\n0.056",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "mod-3-3-correlation.html#mtcars-correlation",
    "href": "mod-3-3-correlation.html#mtcars-correlation",
    "title": "18  Correlation",
    "section": "18.13 MTCARS Correlation",
    "text": "18.13 MTCARS Correlation\nWe return to the mtcars dataset and the variables for the weight of each car (in thousands of pounds) and the miles per gallon of each car.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "mod-3-3-correlation.html#correlation-and-causation",
    "href": "mod-3-3-correlation.html#correlation-and-causation",
    "title": "18  Correlation",
    "section": "18.14 Correlation and Causation",
    "text": "18.14 Correlation and Causation\nTo this point, we have examined measures of association rather than measures of causation.\nWe must be careful to understand that while association may imply causation, association, by itself, is not sufficient to conclude a causal relationship exists.\nAssociation is necessary, but not sufficient, for causation\nCorrelation between two variables may be the product of one or more confounding variables. Observational studies may fall victim to confounding variables, leading one to conclude causation exists. For example, assume that 100 patients were sick with a disease with 5% mortality after two weeks. All the patients were given an experimental drug and at the end of two weeks, only 1 patient has died. Obviously the drug has reduced mortality, or has it? What if 10,000 patients were treated and only 1% died?\nWhile the drug is associated with decreased mortality, we have not controlled for other potential confounding variables. The general health of the patients may have been different than the general population. The patients may have received other drugs that are known to reduce mortality. The age of the patients may be lower (higher) than the general population. This is why scientists use double-blind, randomized, placebo-controlled trials to examine the efficacy of new drugs. These trials reduce (but do not eliminate) the possibility of confounding so investigators can examine whether the outcomes of the control (receive placebo) and treatment (receive drug) groups are statistically different.\nA strong association between two variables is suggestive of a causal relationship but we must be cautious. How were the data gathered? Was there a mechanism to reduce the presence of confounding variables? Are the data experimental, that is, random assignment into control and treatment groups? As we move from observational studies to experimental studies, the ability to suggest that association implies causation increases, but, in the end, we must find other methods to explore whether two (or more) variables are causally related.",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "mod-3-3-correlation.html#module-summary",
    "href": "mod-3-3-correlation.html#module-summary",
    "title": "18  Correlation",
    "section": "18.15 Module Summary",
    "text": "18.15 Module Summary\nWe use descriptive statistics to develop an understanding of the properties of the data.\n\nWe have discussed two broad properties of the data:\n\nThe center of the data\nThe spread of the data\n\nWe developed two measures of association (co-movement)\n\nCovariance\nCorrelation\n\nIn the coming modules, we will discuss randomness, the concept of probability, and probability distributions.",
    "crumbs": [
      "Covariance and Correlation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Correlation</span>"
    ]
  }
]