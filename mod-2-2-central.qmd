---
title: "Central Tendency"
format:
  html:
    toc: true
    toc-depth: 3
    toc-location: right
    self-contained: false     # must be false when using webr
urlcolor: blue
filters:
  - webr
execute:
  webR: true
---

```{r setup, echo = FALSE, message = FALSE}

library(dplyr, quietly = TRUE)
library(ggplot2, quietly = TRUE)
library(kableExtra, quietly = TRUE)
library(tidyquant, quietly = TRUE)

```

## Data Properties

The properties of a set of data can be described (in general) by:

-   The **center** of the data.

-   The **spread** of the data.

-   The **shape** of the data

The **center** of the data refers to the measure of central tendency of the data, that is, what is an estimate of the "middle" of the data.

The **spread** of the data refers to how "far apart" observations are in the data relative to center of the data.

There are two typical measures of the **shape** of the data:

-   Are the data symmetrically or asymmetrically distributed around the mean?
-   Are the data concentrated in one tail of the distribution?

The measures of the center, spread, and shape of the data help us understand the properties of the data.

## Population Mean and Sample Average

Recall that **population data** is comprehensive information collected on all members of a group or entity under study. The population is the universe of members of the group.

Recall that **sample data** is a subset of the population data. Samples may range from 1 member of the population of interest to many members of a population of interest.

Let $N$ be the number of members of a specified group.

$N$ defines the size of the population of the group of interest.

Let $n = N - j$ where $0 \le j \le N$.

$n$ is the size of a sample of the population size $N$.

Given a population size $N$, the population mean, $\mu$, is defined as:

$$\mu = \frac{1}{N} \sum_{i = 1}^N x_i$$

For a sample size $n$ from a population size $N$, then the sample average $\bar{x}$ is:

$$\bar{x} = \frac{1}{n} \sum_{i = 1}^n x_i$$ Here we must be careful in our use of language. When we say **mean** we refer to the **population mean**, that is, the mean obtained using all the members of the population. When we say **sample**, we refer to the **sample average**, that is, the average obtained using a subset of the members of the population.

In the example below, we can use the summarize function to determine number of observations, the minimum value for mpg, the maximum value for mpg, and the sample average for mpg.

```{webr-r}

rm(list = ls())

car_stats <- mtcars %>%
  summarize(n_mpg    = n(),
            min_mpg  = min(mpg),
            max_mpg  = max(mpg),
            avg_mpg  = mean(mpg))

kable(car_stats,
      align  = 'c',
      digits = 2,
      col.names = c('N', 'Minimum', 'Maximum', 'Sample Average'))
      
```

## Mean and Median

The population mean, $\mu$, is one measure of the center of the data.

The **population median** is another measure of the center of the data.

The **median** is a value that separates the observations in half.

For a given median, 50% of the observations are below the median value and 50% of the observations are above the median value.Depending on the spread and shape of the data, the mean and median may be relatively close or far apart.

**Outlying observations** can "pull" the mean far from the "center" of the data.

In the example below, we use the **censusapi** package to access the U.S. Census API to obtain data on total population for county and county-equivalent geographies.

*Note the difference between the mtcars example and the census example: the mtcars example is a sample while the census example uses population data*.

We then estimate the following descriptive statistics for the population of geographies:

-   Number of observations

-   Minimum value for population

-   Maximum value for population

-   Median value for population

-   Mean value for population

```{r, message = FALSE}

rm(list = ls())

library(censusapi)
library(dplyr)
library(kableExtra)
library(tidyverse)

county_pop <- getCensus(name = "acs/acs5",
            vintage = 2023,
            key = "9c1637a56ff93f0af6b4b1d0547ea048fe668175",
            vars = c("NAME",
                     "B01001_001E"),
            region = "county:*") %>%
rename(pop = B01001_001E) %>%
summarize(n_pop    = n(),
          min_pop  = min(pop),
          max_pop  = max(pop),
          med_pop  = median(pop),
          mean_pop = mean(pop))

kable(county_pop,
      col.names = c("N", "Minimum", "Maximum",
                    "Median", "Mean"),
      align     = 'c',
      format.args = list(big.mark = ","),
      caption = 'Descriptive Statistics of U.S. Counties - Population') %>%
kable_styling(font_size = 12)

```

## Mean Deviations

We have estimated the population mean ($\mu$) and the sample average ($\bar{x}$).

We can now construct an estimate of how much each observation deviates from the population mean or sample average.

Given the *i-th* observation for a variable $x$, that is, $x_i$, the **mean deviation** of $x_i$ is:

$$d_i = x_i - \mu$$ Given the *i-th* observation for a variable $x$, that is, $x_i$, the **average deviation** of $x_i$ for a sample is:

$$d_i = x_i - \bar{x}$$

The sum of the mean deviations is zero for the population or approximately zero for a sample.

$$\sum_{i = 1}^N d_i = \sum_{i = 1}^N (x_i - \mu) = 0$$

$$\sum_{i = 1}^n d_i = \sum_{i = 1}^n (x_i - \bar{x}) \approx 0$$

## Mean Deviations Example

In the example below, we estimate the sample average deviation for the **mtcars** example. We **select** the miles per gallon variable, estimate the sample average, and then estimate the average deviation for every observation in the sample.

We then output the first five observations to illustrate the estimation of average deviations.

```{webr-r}

rm(list = ls())

data(mtcars)

cars <- mtcars %>%
  select(mpg) %>%
  mutate(mean_mpg = mean(mpg),
         deviation = mpg - mean(mpg))

kable(cars[1:5,],
      col.names = c("MPG", 
                    "Sample Average",
                    "Mean Deviation"),
      align = c('c','c','c'),
      caption = 'Mean Deviations of MT Cars')

```

In this example, we select two variables: miles per gallon and weight.

We estimate the sample average for both variables. We then sum the average deviations for each variable.

The table illustrates, that for the sample, the sum of the average deviations is approximately zero for each of the variables.

```{webr-r}

rm(list = ls())

data(mtcars)

cars <- mtcars %>%
  select(mpg, wt) %>%
  summarize(mean_mpg = mean(mpg),
            dev_mpg  = sum(mpg - mean(mpg)),
            mean_wt  = mean(wt),
            dev_wt   = sum(wt - mean(wt)))

kable(cars,
      col.names = c("Average MPG", 
                    "Sum of MPG Deviations",
                    "Average Weight",
                    "Sum of WT Deviations"),
      align     = 'c',
      digits    = 15,
      caption = 'Mean Deviations of MT Cars')

```

## Trimmed Mean

The U.S. Census population data illustrates how an outlying observation (Los Angeles County) can 'pull' the population mean away from the "center" of the data.

We can **trim** the data to account for the presence of outliers.

**Trimming the data is a *transformation* of the data**

In most cases, 5% to 25% of the data from the ends of the distribution are discarded to estimate the trimmed mean.

The median is a fully truncated mean, that is, the median represents the discard of 50% of the observations from each end of the distribution.

The trimmed mean is less sensitive to outliers and will provide a "reasonable" estimate of the population mean in many cases.

Removing the highest and lowest scores in a competition to obtained a trimmed mean makes the resulting score more robust to outliers.

## Trimmed Mean Example

We estimate the number of observations, minimum and maximum values, and mean and median for population for all U.S. counties using the data from the U.S. Census.

We note that several large counties "pull" the mean population away from the median population.

We can estimate the trimmed mean using the **mean** function with the **trim** option.

The **trimmed mean** removes a specified percentage of the smallest and largest values from a dataset to reduce the impact of outliers.

Note how even with a 5% trim, the mean of the remaining observations quickly approaches the population mean.

Note how the 50% trim results in the population mean.

```{r, message = FALSE}

rm(list = ls())

library(censusapi)
library(dplyr)
library(kableExtra)
library(tidyverse)

county_pop <- getCensus(name = "acs/acs5",
            vintage = 2023,
            key = "9c1637a56ff93f0af6b4b1d0547ea048fe668175",
            vars = c("NAME",
                     "B01001_001E"),
            region = "county:*") %>%
rename(pop = B01001_001E) %>%
summarize(med_pop  = median(pop),
          mean_pop = mean(pop),
          mean_05  = mean(pop, trim = 0.05),
          mean_10  = mean(pop, trim = 0.10),
          mean_20  = mean(pop, trim = 0.20),
          mean_50  = mean(pop, trim = 0.50))

kable(county_pop,
      col.names = c('Median', 'Mean',
                    'Trim 0.05', 'Trim 0.10',
                    'Trim 0.20', 'Trim 0.50'),
      align     = 'c',
      digits    = 2,
      caption = 'Mean and Trimmed Means, County Population') %>%
kable_styling(font_size = 12)

```

## Weighted Mean

Given $N$ observations of $x$ and weights $w_i$, the weighted population mean, $\mu_w$, is

$$\mu_w = \sum_{i = 1}^N w_i \times x_i$$

For the population mean, $\mu$, the weights are equal to $1/N$ or

$$\mu = \frac{1}{N} \sum_{i = 1}^N = \frac{1}{N}x_1 + \frac{1}{N}x_2 + \dots + \frac{1}{N}x_N$$

Given $n$ observations of $x$, the weighted sampel average $\bar{x}_w$, is defined as:

$$\bar{x}_w = \sum_{i = 1}^n w_i \times x_i$$

For the sample average, $\bar{x}$, the weights are equal to $1/n$ or

$$\bar{x} = \frac{1}{n} \sum_{i = 1}^n = \frac{1}{n}x_1 + \frac{1}{n}x_2 + \dots + \frac{1}{n}x_n$$

## Weighted Mean Example

Let's create a data frame with three variables

Let **x** be a vector of squares

Let **wt_1** be a vector of equal weights.

Let **wt_2** be a vector of unequal weights

We estimate the mean using the **mean** function and the weighted mean using the **weighted.mean** function

As expected, using equal weights returns the same value as the **mean** function.

```{webr-r}

rm(list = ls())

df_1 <- data.frame(x    = c(1, 2, 4, 
                            6, 9, 16, 
                            25, 36, 49, 64),
                   wt_1 = c(.125, .125, .125,
                            .125, .125, .125,
                            .125, .125, .125, .125),
                   wt_2 = c(0.05, 0.1, 0.05, 
                            0.05, 0.1, 0.05,
                            0.2, 0.2, 0.1, 0.1))

means_df1 <- df_1 %>%
  summarize(mean_     = mean(x),
            wt_mean_1 = weighted.mean(x, wt_1),
            wt_mean_2 = weighted.mean(x, wt_2))

kable(means_df1,
      col.names = c('Mean', 
                    'Mean (Weights are Equal)',
                    'Mean (Unequal Weights)'),
      align = c('c','c','c'),
      caption = 'Mean and Weighted Means') 

```

## Quantiles and Percentiles

Let the *p-th* quantile be the value in the data for which $100 \times p$ of the data are less than the value.

A **percentile** is the same concept as the **quantile** but the range is 0 to 100.

A **quantile** refers to the 0, 25, 50, 75, and 100 percentiles.

A **quintile** refers to the 0, 20, 40, 60, 80, and 100 percentiles.

A **decile** refers to the 0, 10, 20, 30, 40, 50, 60, 70, 80, 90, and 100 percentiles.

Given sorted data, the *p-th* quantile is at position

$$1 + p \times (n+1)$$

If you want to determine the location of the *p-th* percent,

$$L_p = \frac{p}{100} \times (n+1)$$

## Quantiles and Percentiles Example

-   Clears the environment:

    -   Removes all objects from memory using rm(list = ls()) to ensure a clean workspace.

-   Loads the mtcars dataset:

    -   Uses the built-in R dataset containing car performance data such as miles per gallon, cylinders, and weight.

-   Calculates quantiles for selected variables:

-   Uses reframe() from dplyr to summarize key statistics.

-   Computes quantiles at 0%, 25%, 50%, 75%, and 100% using quantile().

    -   These represent the minimum, first quartile (Q1), median (Q2), third quartile (Q3), and maximum values.

-   Applies the scales::percent() function:

    -   Converts numeric quantile probabilities (0, 0.25, 0.5, etc.) into formatted percentages (0%, 25%, 50%, 75%, 100%).

-   Creates a clean summary table:

-   Uses kable() to display the quantile data in a readable format.

    -   Customizes column names: Percentile, MPG, Cylinders, and Weight.

    -   Centers all columns and adds a caption: “Quantiles of MTCARS”.

-   Improves table appearance:

    -   Uses kable_styling(font_size = 12) from kableExtra to make the table more visually appealing.

```{r, warnings = FALSE}

rm(list = ls())

cars <- mtcars %>%
  reframe(quantile   = scales::percent(c(0, 0.25, 0.5, 0.75 ,1)),
            mpg      = quantile(mpg, c(0, 0.25, 0.5, 0.75, 1)),
            cyl      = quantile(cyl, c(0, 0.25, 0.5, 0.75, 1)),
            wt       = quantile(wt, c(0, 0.25, 0.5, 0.75, 1)))

kable(cars,
      col.names = c('Percentile', 
                    'MPG',
                    'Cyliners',
                    'Weight'),
      align = c('c','c','c','c'),
      caption = 'Quantiles of MTCARS') %>%
kable_styling(font_size = 12)


```
