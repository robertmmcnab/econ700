---
title: "Hypothesis Testing"
format:
  html:
    toc: true
    toc-depth: 3
    toc-location: right
    self-contained: false     # must be false when using webr
urlcolor: blue
filters:
  - webr
execute:
  webR: true
editor: 
  markdown: 
    wrap: 72
---

```{r setup, echo = FALSE, message = FALSE}

library(dplyr, quietly = TRUE)
library(ggplot2, quietly = TRUE)
library(kableExtra, quietly = TRUE)
library(tidyquant, quietly = TRUE)

```

## Terminology

**Hypothesis testing** is a process by which a statement about the value
of a population parameter of interest is rejected or not rejected.

A **null hypothesis** or $H_0$ is statement about a population parameter
and a specific value or there is no difference between two parameters of
interest.

An **alternative hypothesis** or $H_a$ is a statement that states the
existence of a difference between a population parameter and a specific
value or states that there is a difference between two parameters of
interest.

We use data to test whether to reject or fail to reject the null
hypothesis.

**We never accept the null hypothesis nor do we accept the
alternative.**

We either have sufficient empirical evidence to reject $H_0$ or we have
insufficient evidence to reject $H_0$.

## Two-Tailed Hypotheses

$H_0$ will always have an equality as part of the hypothesis.

$H_a$ will not have an equality as part of the hypothesis.

A two-tailed hypothesis can be stated that the population parameter is
equal to a value.

$$H_0 : \mu = k$$

$$H_a: \mu \ne k$$

We will reject the null hypothesis if we have sufficient empirical
evidence that $\mu$ is sufficiently different from $k$.

A two-tailed hypothesis can also be stated that two parameters are equal
to each other under the null.

$$H_0: \mu_1 = \mu_2 \implies H_0: \mu_1 - \mu_2 = 0$$

$$H_a: \mu_1 \ne \mu_2 \implies H_a: \mu_1 - \mu_2 \ne 0$$

## One-Tailed Hypotheses

$H_0$ will always have an equality as part of the hypothesis.

$H_a$ will not have an equality as part of the hypothesis.

For a one-tailed hypothesis, the population parameter under $H_0$ may be
less than or equal to a value of interest.

$$H_0 : \mu \le k$$

$$H_a: \mu > k$$

For a one-tailed hypothesis, the population parameter under $H_0$ may be
greater than or equal to a value of interest.

$$H_0 : \mu \ge k$$

$$H_a: \mu < k$$

A one-tailed hypothesis can also be stated in terms of two parameters.

$$H_0: \mu_1 \le \mu_2 \implies H_0: \mu_1 - \mu_2 \le 0$$

$$H_a: \mu_1 > \mu_2 \implies H_a: \mu_1 - \mu_2 > 0$$

## Hypothesis Example

Assume that mean sales volume is 14 cars a month. A manager implements a
new incentive plan to increase sales and collects data over a six-month
period. What are the null and alternative hypotheses?

If the manager want to examine whether mean sales volume increased and
let $\mu_1$ be the mean sales volume prior to the implementation of the
plan and $\mu_2$ be the mean sales volume after the implementation of
the plan.

In other words, since the manager is really interested if sales
increased $\mu_2 > \mu_1$, we can form a one-tailed hypothesis.

$$H_0: \mu_1 \ge \mu_2 \implies H_0: \mu_1 - \mu_2 \ge 0$$

$$H_0: \mu_1 < \mu_2 \implies H_0: \mu_1 - \mu_2 < 0$$

More specifically:

$$H_0: \mu_{old} \ge \mu_{new} \implies H_0: \mu_{old} - \mu_{new} \ge 0$$

$$H_0: \mu_{old} < \mu_{new} \implies H_0: \mu_{old} - \mu_{new} < 0$$

## Example

Assume that mean filling weight on a production line is 32
ounces/container. A new machine is installed and a sample of cartons is
gathered and weighed. What is the hypothesis to determine whether the
new machine impacted mean filling weight?

Since the question is whether an impact (positive or negative) has
occurred, we can develop a two-tailed hypothesis

$$H_0: \mu_1 = \mu_2 \implies H_0: \mu_1 - \mu_2 = 0$$

$$H_a: \mu_1 \ne \mu_2 \implies H_a: \mu_1 - \mu_2 \ne 0$$More
specifically,

$$H_0: \mu_{old} = \mu_{new} \implies H_0: \mu_{old} - \mu_{new} = 0$$

$$H_a: \mu_{old} \ne \mu_{new} \implies H_a: \mu_{old} - \mu_{new} \ne 0$$Note
that you would reject the null hypothesis if there was sufficient
empirical evidence that the new mean weight was significantly less or
significantly more than the previous weight.

## Type I and Type II Errors

Since we are using sample data to make inferences about population
parameters, our estimates will not be exactly equal to the population
parameter(s) of interest.

A **Type I** error occurs when when we reject $H_0$ but $H_0$ should not
be rejected.

A **Type II** errors occurs when we do not reject $H_0$ but we should
reject $H_0$

From a hypothesis testing perspective, we focus on incorrectly rejecting
$H_0$, that is, concluding that there is sufficient empirical evidence
to reject the null hypothesis.

**The probability of making a Type I error is called the level of
significance.**

We denote the level of significance as $\alpha$.

If $\alpha = 0.05$, then we want to know whether we can reject $H_0$ at
the 5% level of significance.

The greater the consequences of a Type I error, the higher the level of
significance to reduce the probability of incorrectly rejecting $H_0$
when, in fact, it should not be rejected.

## Type I Error Discussion

A Type 1 error occurs when you reject the null hypothesis when you
should not reject the null hypothesis, in other words, you conclude a
statistically significant result exists when it does not exist.

A Type 1 error is a **false positive** error.

Let the significance level be 10%, that is, $\alpha = 0.10$.

This means that we have a 10% chance of incorrectly rejecting the null
hypothesis.

A higher level of significance means that $\alpha$ is smaller.

Let the significance level be 1%, that is, $\alpha = 0.01$.

This means that we now have a 1% chance of incorrectly rejecting the
null hypothesis.

*You conduct a clinical study comparing the mean recovery time of
patients who received a new drug versus patients who received an old
drug. You have decided to conduct a two-tailed hypothesis test comparing
the mean recovery times. You have set your level of significance to 5%.*

$$
H_0: \mu_{old} = \mu_{new}
$$

$$
H_A: \mu_{old} \ne \mu_{new}
$$

*If you obtain a p-value from your test statistic of 0.07, you would
fail to reject the null hypothesis as the p-value of the test is greater
than the level of significance.*

*Now assume you obtain new data and you obtain a p-value of 0.03. Your
p-value is less than the level of significance, so you would reject the
null hypothesis. You should note that the p-value of 0.03 indicates that
the probability of a Type 1 error is 3%, that is, the probability of a
Type 1 error is smaller than the level of significance and non-zero.*

## Type II Error Discussion

A Type II error occurs when you fail to reject the null hypothesis when,
in fact, it should be rejected.

A Type II error is a **false negative** error.

An example of a Type II error is when a doctor uses a test to screen for
a disease and the test returns a negative result (no disease) but the
patient actually has the disease.

The probability of a Type II error is denoted by $\beta$.

There is a trade off between Type I and Type II errors.

*As you decrease the probability of one type of error, you increase the
probability of the other type of error*.

For example, you are examining whether a new type of surgery improves
outcomes for patients. The surgery is costly and invasive. As such, you
want to only reject the null hypothesis of no impact with a high degree
of confidence and so you set the significance level of the test to 1%.

A significance level of 1% is "more stringent" than a significance level
of 5% and this means you require more evidence to reject the null
hypothesis.

**In other words, by increasing the significance level to 1%, you reduce
the likelihood of false positive but you also increase the likelihood of
a false negative.**

The graphic below highlights the trade off between Type I and Type II
errors.

As you increase the level of significance, $\alpha$, you move the
threshold of the test to the right, reducing the likelihood of a Type I
error but increasing the likelihood of a Type II error.

Since we are typically most concerned about a **false positive**, we
focus on Type I errors rather than Type II errors, hence our focus on
the level of statistical significance which is equal to the likelihood
of making a Type I error.

![](images/clipboard-813737596.png)

Image Source:
<http://grasshopper.com/blog/the-errors-of-ab-testing-your-conclusions-can-make-things-worse/>
